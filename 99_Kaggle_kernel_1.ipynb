{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [커널](https://www.kaggle.com/tunguz/eloda-with-feature-engineering-and-stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:07:00.553192Z",
     "start_time": "2019-02-02T14:06:42.597488Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import describe\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:07:00.591985Z",
     "start_time": "2019-02-02T14:07:00.564919Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-02T18:19:36.826Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading Train and Test Data\n",
    "train = pd.read_csv(\"./data/train.csv\", parse_dates=[\"first_active_month\"])\n",
    "test = pd.read_csv(\"./data/test.csv\", parse_dates=[\"first_active_month\"])\n",
    "print(\"{} observations and {} features in train set.\".format(train.shape[0],train.shape[1]))\n",
    "print(\"{} observations and {} features in test set.\".format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:09:56.096000Z",
     "start_time": "2019-02-02T14:07:52.398499Z"
    }
   },
   "outputs": [],
   "source": [
    "hist_trans = pd.read_csv('./data/historical_transactions.csv')\n",
    "new_merchant_trans = pd.read_csv('./data/new_merchant_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:10:01.092240Z",
     "start_time": "2019-02-02T14:09:56.100249Z"
    }
   },
   "outputs": [],
   "source": [
    "for df in [hist_trans,new_merchant_trans]:\n",
    "    df['category_2'].fillna(1.0,inplace=True)\n",
    "    df['category_3'].fillna('A',inplace=True)\n",
    "    df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:10:01.104359Z",
     "start_time": "2019-02-02T14:10:01.096412Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:11:10.476442Z",
     "start_time": "2019-02-02T14:10:01.108760Z"
    }
   },
   "outputs": [],
   "source": [
    "for df in [hist_trans,new_merchant_trans]:\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['year'] = df['purchase_date'].dt.year\n",
    "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "    df['month'] = df['purchase_date'].dt.month\n",
    "    df['dayofweek'] = df['purchase_date'].dt.dayofweek\n",
    "    df['weekend'] = (df.purchase_date.dt.weekday >=5).astype(int)\n",
    "    df['hour'] = df['purchase_date'].dt.hour\n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n",
    "    df['category_1'] = df['category_1'].map({'Y':1, 'N':0}) \n",
    "    #https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/73244\n",
    "    df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30\n",
    "    df['month_diff'] += df['month_lag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:14:49.947473Z",
     "start_time": "2019-02-02T14:11:10.482294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs = {}\n",
    "for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id']:\n",
    "    aggs[col] = ['nunique']\n",
    "\n",
    "aggs['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "aggs['installments'] = ['sum','max','min','mean','var']\n",
    "aggs['purchase_date'] = ['max','min']\n",
    "aggs['month_lag'] = ['max','min','mean','var']\n",
    "aggs['month_diff'] = ['mean']\n",
    "aggs['authorized_flag'] = ['sum', 'mean']\n",
    "aggs['weekend'] = ['sum', 'mean']\n",
    "aggs['category_1'] = ['sum', 'mean']\n",
    "aggs['card_id'] = ['size']\n",
    "\n",
    "for col in ['category_2','category_3']:\n",
    "    hist_trans[col+'_mean'] = hist_trans.groupby([col])['purchase_amount'].transform('mean')\n",
    "    aggs[col+'_mean'] = ['mean']    \n",
    "\n",
    "new_columns = get_new_columns('hist',aggs)\n",
    "hist_trans_group = hist_trans.groupby('card_id').agg(aggs)\n",
    "hist_trans_group.columns = new_columns\n",
    "hist_trans_group.reset_index(drop=False,inplace=True)\n",
    "hist_trans_group['hist_purchase_date_diff'] = (hist_trans_group['hist_purchase_date_max'] - hist_trans_group['hist_purchase_date_min']).dt.days\n",
    "hist_trans_group['hist_purchase_date_average'] = hist_trans_group['hist_purchase_date_diff']/hist_trans_group['hist_card_id_size']\n",
    "hist_trans_group['hist_purchase_date_uptonow'] = (datetime.datetime.today() - hist_trans_group['hist_purchase_date_max']).dt.days\n",
    "train = train.merge(hist_trans_group,on='card_id',how='left')\n",
    "test = test.merge(hist_trans_group,on='card_id',how='left')\n",
    "del hist_trans_group;gc.collect();gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:15:14.954772Z",
     "start_time": "2019-02-02T14:14:49.951752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs = {}\n",
    "for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id']:\n",
    "    aggs[col] = ['nunique']\n",
    "aggs['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "aggs['installments'] = ['sum','max','min','mean','var']\n",
    "aggs['purchase_date'] = ['max','min']\n",
    "aggs['month_lag'] = ['max','min','mean','var']\n",
    "aggs['month_diff'] = ['mean']\n",
    "aggs['weekend'] = ['sum', 'mean']\n",
    "aggs['category_1'] = ['sum', 'mean']\n",
    "aggs['card_id'] = ['size']\n",
    "\n",
    "for col in ['category_2','category_3']:\n",
    "    new_merchant_trans[col+'_mean'] = new_merchant_trans.groupby([col])['purchase_amount'].transform('mean')\n",
    "    aggs[col+'_mean'] = ['mean']\n",
    "    \n",
    "new_columns = get_new_columns('new_hist',aggs)\n",
    "hist_trans_group = new_merchant_trans.groupby('card_id').agg(aggs)\n",
    "hist_trans_group.columns = new_columns\n",
    "hist_trans_group.reset_index(drop=False,inplace=True)\n",
    "hist_trans_group['new_hist_purchase_date_diff'] = (hist_trans_group['new_hist_purchase_date_max'] - hist_trans_group['new_hist_purchase_date_min']).dt.days\n",
    "hist_trans_group['new_hist_purchase_date_average'] = hist_trans_group['new_hist_purchase_date_diff']/hist_trans_group['new_hist_card_id_size']\n",
    "hist_trans_group['new_hist_purchase_date_uptonow'] = (datetime.datetime.today() - hist_trans_group['new_hist_purchase_date_max']).dt.days\n",
    "train = train.merge(hist_trans_group,on='card_id',how='left')\n",
    "test = test.merge(hist_trans_group,on='card_id',how='left')\n",
    "del hist_trans_group;gc.collect();gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:15:17.185634Z",
     "start_time": "2019-02-02T14:15:14.965522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>hist_month_nunique</th>\n",
       "      <th>hist_hour_nunique</th>\n",
       "      <th>hist_weekofyear_nunique</th>\n",
       "      <th>hist_dayofweek_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>new_hist_weekend_sum</th>\n",
       "      <th>new_hist_weekend_mean</th>\n",
       "      <th>new_hist_category_1_sum</th>\n",
       "      <th>new_hist_category_1_mean</th>\n",
       "      <th>new_hist_card_id_size</th>\n",
       "      <th>new_hist_category_2_mean_mean</th>\n",
       "      <th>new_hist_category_3_mean_mean</th>\n",
       "      <th>new_hist_purchase_date_diff</th>\n",
       "      <th>new_hist_purchase_date_average</th>\n",
       "      <th>new_hist_purchase_date_uptonow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-0.550160</td>\n",
       "      <td>-0.592993</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.347826</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.550160</td>\n",
       "      <td>-0.606486</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.549015</td>\n",
       "      <td>-0.592993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.556518</td>\n",
       "      <td>-0.604559</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.555446</td>\n",
       "      <td>-0.588217</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0         2017-06-01  C_ID_92a2005557          5          2          1   \n",
       "1         2017-01-01  C_ID_3d0044924f          4          1          0   \n",
       "2         2016-08-01  C_ID_d639edf6cd          2          2          0   \n",
       "3         2017-09-01  C_ID_186d6a6901          4          3          0   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  hist_month_nunique  hist_hour_nunique  hist_weekofyear_nunique  \\\n",
       "0 -0.820283                   9                 23                       35   \n",
       "1  0.392913                  12                 24                       50   \n",
       "2  0.688056                  10                 14                       22   \n",
       "3  0.142495                   6                 16                       20   \n",
       "4 -0.159749                   4                 22                       17   \n",
       "\n",
       "   hist_dayofweek_nunique               ...                \\\n",
       "0                       7               ...                 \n",
       "1                       7               ...                 \n",
       "2                       7               ...                 \n",
       "3                       7               ...                 \n",
       "4                       7               ...                 \n",
       "\n",
       "   new_hist_weekend_sum  new_hist_weekend_mean  new_hist_category_1_sum  \\\n",
       "0                   6.0               0.260870                      0.0   \n",
       "1                   0.0               0.000000                      0.0   \n",
       "2                   1.0               1.000000                      0.0   \n",
       "3                   3.0               0.428571                      1.0   \n",
       "4                  12.0               0.333333                      2.0   \n",
       "\n",
       "   new_hist_category_1_mean  new_hist_card_id_size  \\\n",
       "0                  0.000000                   23.0   \n",
       "1                  0.000000                    6.0   \n",
       "2                  0.000000                    1.0   \n",
       "3                  0.142857                    7.0   \n",
       "4                  0.055556                   36.0   \n",
       "\n",
       "   new_hist_category_2_mean_mean  new_hist_category_3_mean_mean  \\\n",
       "0                      -0.550160                      -0.592993   \n",
       "1                      -0.550160                      -0.606486   \n",
       "2                      -0.549015                      -0.592993   \n",
       "3                      -0.556518                      -0.604559   \n",
       "4                      -0.555446                      -0.588217   \n",
       "\n",
       "   new_hist_purchase_date_diff  new_hist_purchase_date_average  \\\n",
       "0                         54.0                        2.347826   \n",
       "1                         56.0                        9.333333   \n",
       "2                          0.0                        0.000000   \n",
       "3                         41.0                        5.857143   \n",
       "4                         57.0                        1.583333   \n",
       "\n",
       "   new_hist_purchase_date_uptonow  \n",
       "0                           279.0  \n",
       "1                           309.0  \n",
       "2                           280.0  \n",
       "3                           290.0  \n",
       "4                           280.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del hist_trans;gc.collect()\n",
    "del new_merchant_trans;gc.collect()\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:15:17.491269Z",
     "start_time": "2019-02-02T14:15:17.188624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['outliers'] = 0\n",
    "train.loc[train['target'] < -30, 'outliers'] = 1\n",
    "train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:15:19.072682Z",
     "start_time": "2019-02-02T14:15:17.496395Z"
    }
   },
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['dayofweek'] = df['first_active_month'].dt.dayofweek\n",
    "    df['weekofyear'] = df['first_active_month'].dt.weekofyear\n",
    "    df['month'] = df['first_active_month'].dt.month\n",
    "    df['elapsed_time'] = (datetime.datetime.today() - df['first_active_month']).dt.days\n",
    "    df['hist_first_buy'] = (df['hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['new_hist_first_buy'] = (df['new_hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    for f in ['hist_purchase_date_max','hist_purchase_date_min','new_hist_purchase_date_max',\\\n",
    "                     'new_hist_purchase_date_min']:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "    df['card_id_total'] = df['new_hist_card_id_size']+df['hist_card_id_size']\n",
    "    df['purchase_amount_total'] = df['new_hist_purchase_amount_sum']+df['hist_purchase_amount_sum']\n",
    "\n",
    "for f in ['feature_1','feature_2','feature_3']:\n",
    "    order_label = train.groupby([f])['outliers'].mean()\n",
    "    train[f] = train[f].map(order_label)\n",
    "    test[f] = test[f].map(order_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:15:19.170531Z",
     "start_time": "2019-02-02T14:15:19.076998Z"
    }
   },
   "outputs": [],
   "source": [
    "train_columns = [c for c in train.columns if c not in ['card_id', 'first_active_month','target','outliers']]\n",
    "target = train['target']\n",
    "del train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:16:27.003059Z",
     "start_time": "2019-02-02T14:15:19.173430Z"
    }
   },
   "outputs": [],
   "source": [
    "train[train_columns].to_csv('./train_3.csv', index=False)\n",
    "test[train_columns].to_csv('./test_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T14:24:10.229886Z",
     "start_time": "2019-02-02T14:16:27.007727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.66406\tvalid_1's rmse: 3.71634\n",
      "[200]\ttraining's rmse: 3.58719\tvalid_1's rmse: 3.68578\n",
      "[300]\ttraining's rmse: 3.53919\tvalid_1's rmse: 3.67536\n",
      "[400]\ttraining's rmse: 3.50211\tvalid_1's rmse: 3.66952\n",
      "[500]\ttraining's rmse: 3.47231\tvalid_1's rmse: 3.66594\n",
      "[600]\ttraining's rmse: 3.44662\tvalid_1's rmse: 3.66281\n",
      "[700]\ttraining's rmse: 3.42433\tvalid_1's rmse: 3.66156\n",
      "[800]\ttraining's rmse: 3.40411\tvalid_1's rmse: 3.66034\n",
      "[900]\ttraining's rmse: 3.38548\tvalid_1's rmse: 3.65966\n",
      "[1000]\ttraining's rmse: 3.36787\tvalid_1's rmse: 3.6592\n",
      "[1100]\ttraining's rmse: 3.35161\tvalid_1's rmse: 3.65924\n",
      "Early stopping, best iteration is:\n",
      "[986]\ttraining's rmse: 3.37044\tvalid_1's rmse: 3.65897\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.66313\tvalid_1's rmse: 3.72753\n",
      "[200]\ttraining's rmse: 3.58493\tvalid_1's rmse: 3.69647\n",
      "[300]\ttraining's rmse: 3.53752\tvalid_1's rmse: 3.68406\n",
      "[400]\ttraining's rmse: 3.50116\tvalid_1's rmse: 3.67686\n",
      "[500]\ttraining's rmse: 3.47209\tvalid_1's rmse: 3.67121\n",
      "[600]\ttraining's rmse: 3.44611\tvalid_1's rmse: 3.66801\n",
      "[700]\ttraining's rmse: 3.42366\tvalid_1's rmse: 3.66581\n",
      "[800]\ttraining's rmse: 3.4029\tvalid_1's rmse: 3.6645\n",
      "[900]\ttraining's rmse: 3.3842\tvalid_1's rmse: 3.66333\n",
      "[1000]\ttraining's rmse: 3.36666\tvalid_1's rmse: 3.66316\n",
      "[1100]\ttraining's rmse: 3.34968\tvalid_1's rmse: 3.66235\n",
      "[1200]\ttraining's rmse: 3.33402\tvalid_1's rmse: 3.66214\n",
      "[1300]\ttraining's rmse: 3.31873\tvalid_1's rmse: 3.66154\n",
      "[1400]\ttraining's rmse: 3.30323\tvalid_1's rmse: 3.66113\n",
      "[1500]\ttraining's rmse: 3.28865\tvalid_1's rmse: 3.66118\n",
      "[1600]\ttraining's rmse: 3.27513\tvalid_1's rmse: 3.66109\n",
      "[1700]\ttraining's rmse: 3.26163\tvalid_1's rmse: 3.66111\n",
      "[1800]\ttraining's rmse: 3.24774\tvalid_1's rmse: 3.66092\n",
      "[1900]\ttraining's rmse: 3.23437\tvalid_1's rmse: 3.66032\n",
      "[2000]\ttraining's rmse: 3.22228\tvalid_1's rmse: 3.65991\n",
      "[2100]\ttraining's rmse: 3.20894\tvalid_1's rmse: 3.66027\n",
      "[2200]\ttraining's rmse: 3.19677\tvalid_1's rmse: 3.66016\n",
      "Early stopping, best iteration is:\n",
      "[2024]\ttraining's rmse: 3.21933\tvalid_1's rmse: 3.6598\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.66804\tvalid_1's rmse: 3.70666\n",
      "[200]\ttraining's rmse: 3.59102\tvalid_1's rmse: 3.67351\n",
      "[300]\ttraining's rmse: 3.5438\tvalid_1's rmse: 3.66009\n",
      "[400]\ttraining's rmse: 3.50699\tvalid_1's rmse: 3.65311\n",
      "[500]\ttraining's rmse: 3.47843\tvalid_1's rmse: 3.64804\n",
      "[600]\ttraining's rmse: 3.45357\tvalid_1's rmse: 3.64455\n",
      "[700]\ttraining's rmse: 3.43037\tvalid_1's rmse: 3.64258\n",
      "[800]\ttraining's rmse: 3.40993\tvalid_1's rmse: 3.64116\n",
      "[900]\ttraining's rmse: 3.39093\tvalid_1's rmse: 3.64037\n",
      "[1000]\ttraining's rmse: 3.37353\tvalid_1's rmse: 3.63935\n",
      "[1100]\ttraining's rmse: 3.35658\tvalid_1's rmse: 3.63881\n",
      "[1200]\ttraining's rmse: 3.34082\tvalid_1's rmse: 3.63872\n",
      "[1300]\ttraining's rmse: 3.32529\tvalid_1's rmse: 3.63877\n",
      "[1400]\ttraining's rmse: 3.31055\tvalid_1's rmse: 3.63849\n",
      "[1500]\ttraining's rmse: 3.29595\tvalid_1's rmse: 3.63854\n",
      "[1600]\ttraining's rmse: 3.28124\tvalid_1's rmse: 3.63851\n",
      "[1700]\ttraining's rmse: 3.26645\tvalid_1's rmse: 3.63839\n",
      "[1800]\ttraining's rmse: 3.2534\tvalid_1's rmse: 3.63818\n",
      "[1900]\ttraining's rmse: 3.23979\tvalid_1's rmse: 3.6381\n",
      "[2000]\ttraining's rmse: 3.22671\tvalid_1's rmse: 3.6381\n",
      "Early stopping, best iteration is:\n",
      "[1878]\ttraining's rmse: 3.24291\tvalid_1's rmse: 3.63794\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.6685\tvalid_1's rmse: 3.71492\n",
      "[200]\ttraining's rmse: 3.59203\tvalid_1's rmse: 3.68376\n",
      "[300]\ttraining's rmse: 3.54507\tvalid_1's rmse: 3.67248\n",
      "[400]\ttraining's rmse: 3.50773\tvalid_1's rmse: 3.6658\n",
      "[500]\ttraining's rmse: 3.47898\tvalid_1's rmse: 3.66208\n",
      "[600]\ttraining's rmse: 3.45384\tvalid_1's rmse: 3.659\n",
      "[700]\ttraining's rmse: 3.43094\tvalid_1's rmse: 3.65803\n",
      "[800]\ttraining's rmse: 3.41017\tvalid_1's rmse: 3.65741\n",
      "[900]\ttraining's rmse: 3.39246\tvalid_1's rmse: 3.65748\n",
      "[1000]\ttraining's rmse: 3.3749\tvalid_1's rmse: 3.65726\n",
      "[1100]\ttraining's rmse: 3.35833\tvalid_1's rmse: 3.65778\n",
      "Early stopping, best iteration is:\n",
      "[937]\ttraining's rmse: 3.38604\tvalid_1's rmse: 3.65681\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.66454\tvalid_1's rmse: 3.72423\n",
      "[200]\ttraining's rmse: 3.58736\tvalid_1's rmse: 3.69571\n",
      "[300]\ttraining's rmse: 3.53962\tvalid_1's rmse: 3.68379\n",
      "[400]\ttraining's rmse: 3.50273\tvalid_1's rmse: 3.67649\n",
      "[500]\ttraining's rmse: 3.47269\tvalid_1's rmse: 3.67203\n",
      "[600]\ttraining's rmse: 3.44784\tvalid_1's rmse: 3.66889\n",
      "[700]\ttraining's rmse: 3.42428\tvalid_1's rmse: 3.66665\n",
      "[800]\ttraining's rmse: 3.40408\tvalid_1's rmse: 3.66555\n",
      "[900]\ttraining's rmse: 3.38513\tvalid_1's rmse: 3.66476\n",
      "[1000]\ttraining's rmse: 3.36675\tvalid_1's rmse: 3.66399\n",
      "[1100]\ttraining's rmse: 3.34965\tvalid_1's rmse: 3.66319\n",
      "[1200]\ttraining's rmse: 3.33417\tvalid_1's rmse: 3.66302\n",
      "[1300]\ttraining's rmse: 3.31944\tvalid_1's rmse: 3.66277\n",
      "[1400]\ttraining's rmse: 3.30505\tvalid_1's rmse: 3.6626\n",
      "[1500]\ttraining's rmse: 3.29154\tvalid_1's rmse: 3.66228\n",
      "[1600]\ttraining's rmse: 3.27674\tvalid_1's rmse: 3.66184\n",
      "[1700]\ttraining's rmse: 3.26343\tvalid_1's rmse: 3.66133\n",
      "[1800]\ttraining's rmse: 3.24967\tvalid_1's rmse: 3.66145\n",
      "Early stopping, best iteration is:\n",
      "[1659]\ttraining's rmse: 3.26884\tvalid_1's rmse: 3.66129\n",
      "CV score: 3.65497 \n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         \"random_state\": 4590}\n",
    "\n",
    "oof_lgb_3 = np.zeros(len(train))\n",
    "predictions_lgb_3 = np.zeros(len(test))\n",
    "start = time.time()\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train,train['outliers'].values)):    \n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][train_columns], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][train_columns], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof_lgb_3[val_idx] = clf.predict(train.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb_3 += clf.predict(test[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "np.save('oof_lgb_3', oof_lgb_3)\n",
    "np.save('predictions_lgb_3', predictions_lgb_3)\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_lgb_3, target)**0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
