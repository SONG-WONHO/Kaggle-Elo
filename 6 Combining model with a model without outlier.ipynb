{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T08:10:53.418817Z",
     "start_time": "2019-02-08T08:10:50.785627Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T08:10:53.771145Z",
     "start_time": "2019-02-08T08:10:53.426167Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T08:10:53.781607Z",
     "start_time": "2019-02-08T08:10:53.774203Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T08:10:53.799637Z",
     "start_time": "2019-02-08T08:10:53.790301Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통합 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T09:00:01.367955Z",
     "start_time": "2019-02-08T09:00:01.359915Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_features(data, keyword, debug=False):\n",
    "    if debug:\n",
    "        data = data[:1000]\n",
    "        \n",
    "    logits = []\n",
    "    for col in data.columns:\n",
    "        if keyword in col:\n",
    "            logits.append(col)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T08:58:44.112080Z",
     "start_time": "2019-02-08T08:58:44.101135Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T08:59:22.466781Z",
     "start_time": "2019-02-08T08:58:44.339017Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + 'train_v3.csv')\n",
    "test = pd.read_csv(path + 'test_v3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제거할 피처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T09:07:37.311900Z",
     "start_time": "2019-02-08T09:07:37.303052Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATS_EXCLUDED = ['first_active', 'card_id', 'target', 'outliers',\n",
    "                  'hist_purchase_date_max', 'hist_purchase_date_min', \n",
    "                  'new_purchase_date_max', 'new_purchase_date_min']\n",
    "\n",
    "# FEATS_EXCLUDED += drop_features(train, 'hist_duration')\n",
    "# FEATS_EXCLUDED += drop_features(train, 'hist_amount_month_ratio')\n",
    "# FEATS_EXCLUDED += drop_features(train, 'new_duration')\n",
    "# FEATS_EXCLUDED += drop_features(train, 'new_amount_month_ratio')\n",
    "\n",
    "FEATS_EXCLUDED += drop_features(train, 'hist_price')\n",
    "FEATS_EXCLUDED += drop_features(train, 'new_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T09:07:37.587848Z",
     "start_time": "2019-02-08T09:07:37.576209Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         \"random_state\": 4590}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T09:17:33.282408Z",
     "start_time": "2019-02-08T09:07:37.864881Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.65164\tvalid_1's rmse: 3.71639\n",
      "[200]\ttraining's rmse: 3.56694\tvalid_1's rmse: 3.68553\n",
      "[300]\ttraining's rmse: 3.51088\tvalid_1's rmse: 3.67429\n",
      "[400]\ttraining's rmse: 3.46854\tvalid_1's rmse: 3.66765\n",
      "[500]\ttraining's rmse: 3.43272\tvalid_1's rmse: 3.66397\n",
      "[600]\ttraining's rmse: 3.40279\tvalid_1's rmse: 3.66193\n",
      "[700]\ttraining's rmse: 3.37552\tvalid_1's rmse: 3.66045\n",
      "[800]\ttraining's rmse: 3.35106\tvalid_1's rmse: 3.66002\n",
      "[900]\ttraining's rmse: 3.32785\tvalid_1's rmse: 3.65936\n",
      "[1000]\ttraining's rmse: 3.30671\tvalid_1's rmse: 3.65828\n",
      "[1100]\ttraining's rmse: 3.28663\tvalid_1's rmse: 3.65774\n",
      "[1200]\ttraining's rmse: 3.26755\tvalid_1's rmse: 3.65795\n",
      "[1300]\ttraining's rmse: 3.24905\tvalid_1's rmse: 3.65808\n",
      "Early stopping, best iteration is:\n",
      "[1148]\ttraining's rmse: 3.27725\tvalid_1's rmse: 3.65762\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.64991\tvalid_1's rmse: 3.72726\n",
      "[200]\ttraining's rmse: 3.56337\tvalid_1's rmse: 3.69699\n",
      "[300]\ttraining's rmse: 3.50801\tvalid_1's rmse: 3.68363\n",
      "[400]\ttraining's rmse: 3.4639\tvalid_1's rmse: 3.67514\n",
      "[500]\ttraining's rmse: 3.42907\tvalid_1's rmse: 3.67011\n",
      "[600]\ttraining's rmse: 3.39853\tvalid_1's rmse: 3.66691\n",
      "[700]\ttraining's rmse: 3.37177\tvalid_1's rmse: 3.66541\n",
      "[800]\ttraining's rmse: 3.34664\tvalid_1's rmse: 3.66475\n",
      "[900]\ttraining's rmse: 3.32431\tvalid_1's rmse: 3.66419\n",
      "[1000]\ttraining's rmse: 3.30276\tvalid_1's rmse: 3.66334\n",
      "[1100]\ttraining's rmse: 3.2822\tvalid_1's rmse: 3.66288\n",
      "[1200]\ttraining's rmse: 3.26272\tvalid_1's rmse: 3.66265\n",
      "[1300]\ttraining's rmse: 3.24474\tvalid_1's rmse: 3.66178\n",
      "[1400]\ttraining's rmse: 3.22664\tvalid_1's rmse: 3.66126\n",
      "[1500]\ttraining's rmse: 3.21033\tvalid_1's rmse: 3.66094\n",
      "[1600]\ttraining's rmse: 3.19378\tvalid_1's rmse: 3.6608\n",
      "[1700]\ttraining's rmse: 3.17736\tvalid_1's rmse: 3.66108\n",
      "[1800]\ttraining's rmse: 3.16201\tvalid_1's rmse: 3.66059\n",
      "[1900]\ttraining's rmse: 3.14653\tvalid_1's rmse: 3.6604\n",
      "[2000]\ttraining's rmse: 3.13155\tvalid_1's rmse: 3.66042\n",
      "Early stopping, best iteration is:\n",
      "[1867]\ttraining's rmse: 3.15094\tvalid_1's rmse: 3.66009\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.65401\tvalid_1's rmse: 3.71066\n",
      "[200]\ttraining's rmse: 3.56954\tvalid_1's rmse: 3.67757\n",
      "[300]\ttraining's rmse: 3.51485\tvalid_1's rmse: 3.66372\n",
      "[400]\ttraining's rmse: 3.47333\tvalid_1's rmse: 3.65645\n",
      "[500]\ttraining's rmse: 3.43768\tvalid_1's rmse: 3.65145\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-d697e65c7fda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mnum_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0moof_lgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    214\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1758\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1760\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1761\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1762\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "train_columns = [f for f in train.columns if f not in FEATS_EXCLUDED]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train['outliers'].values)):    \n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][train_columns], label=train.iloc[trn_idx]['target'])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][train_columns], label=train.iloc[val_idx]['target'])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof_lgb[val_idx] = clf.predict(train.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(test[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"Feature\"] = train_columns\n",
    "    fold_importance[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_ + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(train.target.values, oof_lgb)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T09:18:37.644365Z",
     "start_time": "2019-02-08T09:18:37.602956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>new_authorized_flag_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>hist_purchase_year_mode</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>hist_purchase_year_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>hist_purchase_year_max</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>hist_purchase_year_min</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>feature_min</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>hist_last_buy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>new_purchase_year_min</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>new_purchase_year_max</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>hist_category_3_min_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>feature_3_outlier</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>new_purchase_year_mode</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>new_purchase_year_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>hist_category_2_min_mean</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>hist_first_buy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>first_active_quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>hist_purchase_weekend_mode</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>new_purchase_amount_over_550</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>hist_purchase_amount_over_550</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>new_last_buy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>hist_purchase_year_nunique</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>new_category_3_mode</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>new_purchase_weekend_mode</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>hist_purchase_dayofweek_min</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>new_month_diff_min</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>new_authorized_flag_mode</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>new_month_diff_mean</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>feature_max</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>new_card_id_size</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>hist_month_lag_sum</td>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>hist_month_diff_mean</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>new_purchase_amount_mean</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>new_purchase_date_average</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>new_purchase_weekofyear_mean</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>hist_purchase_hour_var</td>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>new_Black_Friday_2017_mean</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>new_category_1_sum</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>hist_purchase_weekofyear_nunique</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>hist_purchase_date_uptonow</td>\n",
       "      <td>305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>new_category_1_mean</td>\n",
       "      <td>305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>new_purchase_weekofyear_max</td>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>hist_installments_sum</td>\n",
       "      <td>324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>hist_fathers_day_2017_mean</td>\n",
       "      <td>332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>hist_category_1_label_mean</td>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>new_duration_max</td>\n",
       "      <td>350</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>hist_merchant_id_nunique</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>card_id_size_ratio</td>\n",
       "      <td>361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>new_purchase_date_diff</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>category_1_mean</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>new_purchase_day_mean</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>hist_duration_mean</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>hist_Children_day_2017_mean</td>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>new_purchase_amount_max</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>hist_duration_min</td>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>hist_purchase_month_nunique</td>\n",
       "      <td>470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>hist_category_1_label_sum</td>\n",
       "      <td>508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>new_month_lag_mean</td>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>first_active_total_day_outlier</td>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>hist_authorized_flag_label_mean</td>\n",
       "      <td>678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Feature  importance  fold\n",
       "153          new_authorized_flag_mean           0     1\n",
       "80            hist_purchase_year_mode           0     1\n",
       "82            hist_purchase_year_mean           0     1\n",
       "83             hist_purchase_year_max           0     1\n",
       "84             hist_purchase_year_min           0     1\n",
       "26                        feature_min           0     1\n",
       "261                     hist_last_buy           0     1\n",
       "202             new_purchase_year_min           0     1\n",
       "201             new_purchase_year_max           0     1\n",
       "144          hist_category_3_min_mean           0     1\n",
       "19                  feature_3_outlier           0     1\n",
       "198            new_purchase_year_mode           0     1\n",
       "200            new_purchase_year_mean           0     1\n",
       "140          hist_category_2_min_mean           0     1\n",
       "260                    hist_first_buy           0     1\n",
       "5                first_active_quarter           0     1\n",
       "114        hist_purchase_weekend_mode           0     1\n",
       "185      new_purchase_amount_over_550           0     1\n",
       "67      hist_purchase_amount_over_550           0     1\n",
       "263                      new_last_buy           1     1\n",
       "81         hist_purchase_year_nunique           1     1\n",
       "2                           feature_3           1     1\n",
       "167               new_category_3_mode           1     1\n",
       "232         new_purchase_weekend_mode           1     1\n",
       "108       hist_purchase_dayofweek_min           1     1\n",
       "236                new_month_diff_min           1     1\n",
       "151          new_authorized_flag_mode           1     1\n",
       "237               new_month_diff_mean           1     1\n",
       "25                        feature_max           2     1\n",
       "154                  new_card_id_size           2     1\n",
       "..                                ...         ...   ...\n",
       "55                 hist_month_lag_sum         277     1\n",
       "119              hist_month_diff_mean         278     1\n",
       "180          new_purchase_amount_mean         278     1\n",
       "257         new_purchase_date_average         278     1\n",
       "229      new_purchase_weekofyear_mean         280     1\n",
       "100            hist_purchase_hour_var         299     1\n",
       "242        new_Black_Friday_2017_mean         301     1\n",
       "158                new_category_1_sum         303     1\n",
       "110  hist_purchase_weekofyear_nunique         303     1\n",
       "149        hist_purchase_date_uptonow         305     1\n",
       "159               new_category_1_mean         305     1\n",
       "230       new_purchase_weekofyear_max         314     1\n",
       "43              hist_installments_sum         324     1\n",
       "124        hist_fathers_day_2017_mean         332     1\n",
       "41         hist_category_1_label_mean         336     1\n",
       "246                  new_duration_max         350     1\n",
       "53           hist_merchant_id_nunique         360     1\n",
       "265                card_id_size_ratio         361     1\n",
       "256            new_purchase_date_diff         364     1\n",
       "276                   category_1_mean         371     1\n",
       "210             new_purchase_day_mean         380     1\n",
       "129                hist_duration_mean         381     1\n",
       "125       hist_Children_day_2017_mean         382     1\n",
       "182           new_purchase_amount_max         388     1\n",
       "130                 hist_duration_min         397     1\n",
       "86        hist_purchase_month_nunique         470     1\n",
       "40          hist_category_1_label_sum         508     1\n",
       "174                new_month_lag_mean         516     1\n",
       "22     first_active_total_day_outlier         588     1\n",
       "35    hist_authorized_flag_label_mean         678     1\n",
       "\n",
       "[293 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[feature_importance.fold == 1].sort_values('importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이상치 없는 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:03:01.402717Z",
     "start_time": "2019-02-08T07:03:01.398729Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:03:16.953232Z",
     "start_time": "2019-02-08T07:03:01.547966Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + 'train_v3.csv')\n",
    "test = pd.read_csv(path + 'test_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:03:29.283667Z",
     "start_time": "2019-02-08T07:03:29.022371Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train[train.outliers == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제거할 피처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:03:30.002901Z",
     "start_time": "2019-02-08T07:03:30.000930Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATS_EXCLUDED = ['first_active', 'card_id', 'target', 'outliers',\n",
    "                  'hist_purchase_date_max', 'hist_purchase_date_min', \n",
    "                  'new_purchase_date_max', 'new_purchase_date_min']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:03:30.385738Z",
     "start_time": "2019-02-08T07:03:30.381748Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         \"random_state\": 4590}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:21:44.604209Z",
     "start_time": "2019-02-08T07:03:33.148134Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.60508\tvalid_1's rmse: 1.61676\n",
      "[200]\ttraining's rmse: 1.57258\tvalid_1's rmse: 1.58947\n",
      "[300]\ttraining's rmse: 1.5569\tvalid_1's rmse: 1.57843\n",
      "[400]\ttraining's rmse: 1.54652\tvalid_1's rmse: 1.57278\n",
      "[500]\ttraining's rmse: 1.53831\tvalid_1's rmse: 1.56901\n",
      "[600]\ttraining's rmse: 1.53133\tvalid_1's rmse: 1.56669\n",
      "[700]\ttraining's rmse: 1.52511\tvalid_1's rmse: 1.56515\n",
      "[800]\ttraining's rmse: 1.51955\tvalid_1's rmse: 1.56427\n",
      "[900]\ttraining's rmse: 1.51443\tvalid_1's rmse: 1.5636\n",
      "[1000]\ttraining's rmse: 1.50958\tvalid_1's rmse: 1.56307\n",
      "[1100]\ttraining's rmse: 1.50494\tvalid_1's rmse: 1.56258\n",
      "[1200]\ttraining's rmse: 1.50054\tvalid_1's rmse: 1.56232\n",
      "[1300]\ttraining's rmse: 1.49619\tvalid_1's rmse: 1.56206\n",
      "[1400]\ttraining's rmse: 1.492\tvalid_1's rmse: 1.5618\n",
      "[1500]\ttraining's rmse: 1.4879\tvalid_1's rmse: 1.56166\n",
      "[1600]\ttraining's rmse: 1.48388\tvalid_1's rmse: 1.56144\n",
      "[1700]\ttraining's rmse: 1.47992\tvalid_1's rmse: 1.56131\n",
      "[1800]\ttraining's rmse: 1.47591\tvalid_1's rmse: 1.56122\n",
      "[1900]\ttraining's rmse: 1.47199\tvalid_1's rmse: 1.5611\n",
      "[2000]\ttraining's rmse: 1.46814\tvalid_1's rmse: 1.56108\n",
      "[2100]\ttraining's rmse: 1.46424\tvalid_1's rmse: 1.56107\n",
      "[2200]\ttraining's rmse: 1.46048\tvalid_1's rmse: 1.56106\n",
      "Early stopping, best iteration is:\n",
      "[2009]\ttraining's rmse: 1.46783\tvalid_1's rmse: 1.56104\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.60584\tvalid_1's rmse: 1.61461\n",
      "[200]\ttraining's rmse: 1.57339\tvalid_1's rmse: 1.58669\n",
      "[300]\ttraining's rmse: 1.55754\tvalid_1's rmse: 1.5757\n",
      "[400]\ttraining's rmse: 1.54694\tvalid_1's rmse: 1.57008\n",
      "[500]\ttraining's rmse: 1.53863\tvalid_1's rmse: 1.56661\n",
      "[600]\ttraining's rmse: 1.53148\tvalid_1's rmse: 1.56436\n",
      "[700]\ttraining's rmse: 1.52518\tvalid_1's rmse: 1.56301\n",
      "[800]\ttraining's rmse: 1.51953\tvalid_1's rmse: 1.56204\n",
      "[900]\ttraining's rmse: 1.51431\tvalid_1's rmse: 1.56134\n",
      "[1000]\ttraining's rmse: 1.50943\tvalid_1's rmse: 1.56088\n",
      "[1100]\ttraining's rmse: 1.50482\tvalid_1's rmse: 1.56052\n",
      "[1200]\ttraining's rmse: 1.50026\tvalid_1's rmse: 1.56021\n",
      "[1300]\ttraining's rmse: 1.49585\tvalid_1's rmse: 1.55998\n",
      "[1400]\ttraining's rmse: 1.49155\tvalid_1's rmse: 1.5597\n",
      "[1500]\ttraining's rmse: 1.48751\tvalid_1's rmse: 1.5596\n",
      "[1600]\ttraining's rmse: 1.48351\tvalid_1's rmse: 1.55945\n",
      "[1700]\ttraining's rmse: 1.47957\tvalid_1's rmse: 1.55936\n",
      "[1800]\ttraining's rmse: 1.47572\tvalid_1's rmse: 1.55924\n",
      "[1900]\ttraining's rmse: 1.47172\tvalid_1's rmse: 1.55916\n",
      "[2000]\ttraining's rmse: 1.46794\tvalid_1's rmse: 1.55911\n",
      "[2100]\ttraining's rmse: 1.46406\tvalid_1's rmse: 1.55906\n",
      "[2200]\ttraining's rmse: 1.4604\tvalid_1's rmse: 1.55904\n",
      "[2300]\ttraining's rmse: 1.45669\tvalid_1's rmse: 1.55894\n",
      "[2400]\ttraining's rmse: 1.453\tvalid_1's rmse: 1.5589\n",
      "[2500]\ttraining's rmse: 1.44937\tvalid_1's rmse: 1.55896\n",
      "Early stopping, best iteration is:\n",
      "[2340]\ttraining's rmse: 1.45518\tvalid_1's rmse: 1.55886\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.61072\tvalid_1's rmse: 1.59327\n",
      "[200]\ttraining's rmse: 1.57845\tvalid_1's rmse: 1.56552\n",
      "[300]\ttraining's rmse: 1.56276\tvalid_1's rmse: 1.55478\n",
      "[400]\ttraining's rmse: 1.55234\tvalid_1's rmse: 1.54917\n",
      "[500]\ttraining's rmse: 1.54409\tvalid_1's rmse: 1.54587\n",
      "[600]\ttraining's rmse: 1.53698\tvalid_1's rmse: 1.54351\n",
      "[700]\ttraining's rmse: 1.53075\tvalid_1's rmse: 1.54193\n",
      "[800]\ttraining's rmse: 1.52514\tvalid_1's rmse: 1.54095\n",
      "[900]\ttraining's rmse: 1.51991\tvalid_1's rmse: 1.54028\n",
      "[1000]\ttraining's rmse: 1.51496\tvalid_1's rmse: 1.5397\n",
      "[1100]\ttraining's rmse: 1.5103\tvalid_1's rmse: 1.53929\n",
      "[1200]\ttraining's rmse: 1.50583\tvalid_1's rmse: 1.53903\n",
      "[1300]\ttraining's rmse: 1.50156\tvalid_1's rmse: 1.53884\n",
      "[1400]\ttraining's rmse: 1.49735\tvalid_1's rmse: 1.53867\n",
      "[1500]\ttraining's rmse: 1.49316\tvalid_1's rmse: 1.53842\n",
      "[1600]\ttraining's rmse: 1.48908\tvalid_1's rmse: 1.53824\n",
      "[1700]\ttraining's rmse: 1.48513\tvalid_1's rmse: 1.5382\n",
      "[1800]\ttraining's rmse: 1.48117\tvalid_1's rmse: 1.53814\n",
      "[1900]\ttraining's rmse: 1.47719\tvalid_1's rmse: 1.53812\n",
      "[2000]\ttraining's rmse: 1.47332\tvalid_1's rmse: 1.53811\n",
      "[2100]\ttraining's rmse: 1.46949\tvalid_1's rmse: 1.53796\n",
      "[2200]\ttraining's rmse: 1.46578\tvalid_1's rmse: 1.53788\n",
      "[2300]\ttraining's rmse: 1.46198\tvalid_1's rmse: 1.53771\n",
      "[2400]\ttraining's rmse: 1.45823\tvalid_1's rmse: 1.53766\n",
      "[2500]\ttraining's rmse: 1.45458\tvalid_1's rmse: 1.53766\n",
      "[2600]\ttraining's rmse: 1.45098\tvalid_1's rmse: 1.53763\n",
      "[2700]\ttraining's rmse: 1.44753\tvalid_1's rmse: 1.53766\n",
      "[2800]\ttraining's rmse: 1.44397\tvalid_1's rmse: 1.53755\n",
      "[2900]\ttraining's rmse: 1.44049\tvalid_1's rmse: 1.53756\n",
      "[3000]\ttraining's rmse: 1.43708\tvalid_1's rmse: 1.53756\n",
      "Early stopping, best iteration is:\n",
      "[2827]\ttraining's rmse: 1.44299\tvalid_1's rmse: 1.53752\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.60593\tvalid_1's rmse: 1.61355\n",
      "[200]\ttraining's rmse: 1.57368\tvalid_1's rmse: 1.58562\n",
      "[300]\ttraining's rmse: 1.55802\tvalid_1's rmse: 1.57458\n",
      "[400]\ttraining's rmse: 1.54765\tvalid_1's rmse: 1.569\n",
      "[500]\ttraining's rmse: 1.53949\tvalid_1's rmse: 1.56552\n",
      "[600]\ttraining's rmse: 1.53253\tvalid_1's rmse: 1.56334\n",
      "[700]\ttraining's rmse: 1.52628\tvalid_1's rmse: 1.56195\n",
      "[800]\ttraining's rmse: 1.52065\tvalid_1's rmse: 1.56101\n",
      "[900]\ttraining's rmse: 1.51555\tvalid_1's rmse: 1.56044\n",
      "[1000]\ttraining's rmse: 1.51064\tvalid_1's rmse: 1.55996\n",
      "[1100]\ttraining's rmse: 1.50611\tvalid_1's rmse: 1.55967\n",
      "[1200]\ttraining's rmse: 1.50167\tvalid_1's rmse: 1.55953\n",
      "[1300]\ttraining's rmse: 1.49734\tvalid_1's rmse: 1.55922\n",
      "[1400]\ttraining's rmse: 1.49322\tvalid_1's rmse: 1.55908\n",
      "[1500]\ttraining's rmse: 1.48899\tvalid_1's rmse: 1.55898\n",
      "[1600]\ttraining's rmse: 1.48502\tvalid_1's rmse: 1.55893\n",
      "[1700]\ttraining's rmse: 1.48107\tvalid_1's rmse: 1.55866\n",
      "[1800]\ttraining's rmse: 1.47718\tvalid_1's rmse: 1.55857\n",
      "[1900]\ttraining's rmse: 1.47327\tvalid_1's rmse: 1.55847\n",
      "[2000]\ttraining's rmse: 1.46946\tvalid_1's rmse: 1.55835\n",
      "[2100]\ttraining's rmse: 1.46566\tvalid_1's rmse: 1.55827\n",
      "[2200]\ttraining's rmse: 1.46196\tvalid_1's rmse: 1.55813\n",
      "[2300]\ttraining's rmse: 1.45828\tvalid_1's rmse: 1.55807\n",
      "[2400]\ttraining's rmse: 1.4545\tvalid_1's rmse: 1.55808\n",
      "[2500]\ttraining's rmse: 1.45083\tvalid_1's rmse: 1.55801\n",
      "[2600]\ttraining's rmse: 1.44723\tvalid_1's rmse: 1.55799\n",
      "[2700]\ttraining's rmse: 1.44368\tvalid_1's rmse: 1.55795\n",
      "Early stopping, best iteration is:\n",
      "[2561]\ttraining's rmse: 1.44862\tvalid_1's rmse: 1.5579\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.60496\tvalid_1's rmse: 1.61764\n",
      "[200]\ttraining's rmse: 1.5728\tvalid_1's rmse: 1.58927\n",
      "[300]\ttraining's rmse: 1.55708\tvalid_1's rmse: 1.57802\n",
      "[400]\ttraining's rmse: 1.5467\tvalid_1's rmse: 1.57251\n",
      "[500]\ttraining's rmse: 1.53848\tvalid_1's rmse: 1.56926\n",
      "[600]\ttraining's rmse: 1.53131\tvalid_1's rmse: 1.56703\n",
      "[700]\ttraining's rmse: 1.5251\tvalid_1's rmse: 1.56561\n",
      "[800]\ttraining's rmse: 1.51946\tvalid_1's rmse: 1.56454\n",
      "[900]\ttraining's rmse: 1.51439\tvalid_1's rmse: 1.56397\n",
      "[1000]\ttraining's rmse: 1.50963\tvalid_1's rmse: 1.56345\n",
      "[1100]\ttraining's rmse: 1.50491\tvalid_1's rmse: 1.56295\n",
      "[1200]\ttraining's rmse: 1.50048\tvalid_1's rmse: 1.5627\n",
      "[1300]\ttraining's rmse: 1.49605\tvalid_1's rmse: 1.56248\n",
      "[1400]\ttraining's rmse: 1.49174\tvalid_1's rmse: 1.56232\n",
      "[1500]\ttraining's rmse: 1.48761\tvalid_1's rmse: 1.56223\n",
      "[1600]\ttraining's rmse: 1.48359\tvalid_1's rmse: 1.56199\n",
      "[1700]\ttraining's rmse: 1.47965\tvalid_1's rmse: 1.56192\n",
      "[1800]\ttraining's rmse: 1.47565\tvalid_1's rmse: 1.56176\n",
      "[1900]\ttraining's rmse: 1.47187\tvalid_1's rmse: 1.56168\n",
      "[2000]\ttraining's rmse: 1.46798\tvalid_1's rmse: 1.56154\n",
      "[2100]\ttraining's rmse: 1.4641\tvalid_1's rmse: 1.56138\n",
      "[2200]\ttraining's rmse: 1.46037\tvalid_1's rmse: 1.56136\n",
      "[2300]\ttraining's rmse: 1.45658\tvalid_1's rmse: 1.56128\n",
      "[2400]\ttraining's rmse: 1.45303\tvalid_1's rmse: 1.56124\n",
      "[2500]\ttraining's rmse: 1.4494\tvalid_1's rmse: 1.56122\n",
      "[2600]\ttraining's rmse: 1.44584\tvalid_1's rmse: 1.56117\n",
      "[2700]\ttraining's rmse: 1.44221\tvalid_1's rmse: 1.56117\n",
      "[2800]\ttraining's rmse: 1.4387\tvalid_1's rmse: 1.5611\n",
      "[2900]\ttraining's rmse: 1.43526\tvalid_1's rmse: 1.56115\n",
      "Early stopping, best iteration is:\n",
      "[2783]\ttraining's rmse: 1.4393\tvalid_1's rmse: 1.56109\n",
      "CV score: 1.55531 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "train_columns = [f for f in train.columns if f not in FEATS_EXCLUDED]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train['outliers'].values)):    \n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][train_columns], label=train.iloc[trn_idx]['target'])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][train_columns], label=train.iloc[val_idx]['target'])\n",
    "    \n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof_lgb[val_idx] = clf.predict(train.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(test[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"Feature\"] = train_columns\n",
    "    fold_importance[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_ + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(train.target.values, oof_lgb)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:24:30.281518Z",
     "start_time": "2019-02-08T07:24:30.275488Z"
    }
   },
   "outputs": [],
   "source": [
    "model_without_outliers = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "model_without_outliers[\"target\"] = predictions_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이상치 예측 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:24:46.031602Z",
     "start_time": "2019-02-08T07:24:31.693473Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + 'train_v3.csv')\n",
    "test = pd.read_csv(path + 'test_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:24:46.086457Z",
     "start_time": "2019-02-08T07:24:46.033599Z"
    }
   },
   "outputs": [],
   "source": [
    "target = train['outliers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제거할 피처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:24:46.091444Z",
     "start_time": "2019-02-08T07:24:46.087454Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATS_EXCLUDED = ['first_active', 'card_id', 'target', 'outliers',\n",
    "                  'hist_purchase_date_max', 'hist_purchase_date_min', \n",
    "                  'new_purchase_date_max', 'new_purchase_date_min']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:24:46.098423Z",
     "start_time": "2019-02-08T07:24:46.093438Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:27:41.525388Z",
     "start_time": "2019-02-08T07:24:46.101416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0439393\tvalid_1's binary_logloss: 0.0466941\n",
      "[200]\ttraining's binary_logloss: 0.0439582\tvalid_1's binary_logloss: 0.0466935\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.0439586\tvalid_1's binary_logloss: 0.0465615\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0439916\tvalid_1's binary_logloss: 0.0471326\n",
      "[200]\ttraining's binary_logloss: 0.044006\tvalid_1's binary_logloss: 0.0471322\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.0439602\tvalid_1's binary_logloss: 0.0470829\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0444197\tvalid_1's binary_logloss: 0.046345\n",
      "[200]\ttraining's binary_logloss: 0.0443985\tvalid_1's binary_logloss: 0.046319\n",
      "[300]\ttraining's binary_logloss: 0.0443899\tvalid_1's binary_logloss: 0.0462997\n",
      "[400]\ttraining's binary_logloss: 0.0443929\tvalid_1's binary_logloss: 0.0462866\n",
      "[500]\ttraining's binary_logloss: 0.0443896\tvalid_1's binary_logloss: 0.0462947\n",
      "[600]\ttraining's binary_logloss: 0.0443942\tvalid_1's binary_logloss: 0.0463057\n",
      "Early stopping, best iteration is:\n",
      "[406]\ttraining's binary_logloss: 0.0443867\tvalid_1's binary_logloss: 0.0462782\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0442598\tvalid_1's binary_logloss: 0.0448344\n",
      "[200]\ttraining's binary_logloss: 0.0442657\tvalid_1's binary_logloss: 0.0448134\n",
      "[300]\ttraining's binary_logloss: 0.0442635\tvalid_1's binary_logloss: 0.0448185\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's binary_logloss: 0.0442536\tvalid_1's binary_logloss: 0.0448076\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0442483\tvalid_1's binary_logloss: 0.0464303\n",
      "[200]\ttraining's binary_logloss: 0.0442343\tvalid_1's binary_logloss: 0.0463916\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's binary_logloss: 0.0442167\tvalid_1's binary_logloss: 0.0464128\n",
      "CV score: 0.04623 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "train_columns = [f for f in train.columns if f not in FEATS_EXCLUDED]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train['outliers'].values)):    \n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][train_columns], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][train_columns], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof_lgb[val_idx] = clf.predict(train.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(test[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"Feature\"] = train_columns\n",
    "    fold_importance[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_ + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(log_loss(target.values, oof_lgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:27:41.533324Z",
     "start_time": "2019-02-08T07:27:41.526342Z"
    }
   },
   "outputs": [],
   "source": [
    "outlier_prob = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "outlier_prob[\"target\"] = predictions_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:28:02.793934Z",
     "start_time": "2019-02-08T07:28:01.622516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x250f9fdb470>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:28:26.920603Z",
     "start_time": "2019-02-08T07:28:26.899659Z"
    }
   },
   "outputs": [],
   "source": [
    "outlier_id = pd.DataFrame(outlier_prob.sort_values(by='target',ascending = False).head(50000)['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:28:28.712224Z",
     "start_time": "2019-02-08T07:28:28.602265Z"
    }
   },
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv(path + 'submission_best_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:28:29.490918Z",
     "start_time": "2019-02-08T07:28:29.430879Z"
    }
   },
   "outputs": [],
   "source": [
    "most_likely_liers = best_submission.merge(outlier_id,how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:28:58.071494Z",
     "start_time": "2019-02-08T07:28:31.439469Z"
    }
   },
   "outputs": [],
   "source": [
    "for card_id in most_likely_liers['card_id']:\n",
    "    model_without_outliers.loc[model_without_outliers['card_id']==card_id,'target'] = most_likely_liers.loc[most_likely_liers['card_id']==card_id,'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T07:28:58.489697Z",
     "start_time": "2019-02-08T07:28:58.073499Z"
    }
   },
   "outputs": [],
   "source": [
    "model_without_outliers.to_csv(\"./data/combining_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
