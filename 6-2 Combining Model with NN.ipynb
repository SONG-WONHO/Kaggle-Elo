{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T08:11:23.049623Z",
     "start_time": "2019-02-14T08:11:20.601154Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T08:11:36.294477Z",
     "start_time": "2019-02-14T08:11:36.283503Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T08:11:38.555764Z",
     "start_time": "2019-02-14T08:11:38.549513Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T08:11:38.830700Z",
     "start_time": "2019-02-14T08:11:38.824339Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T08:12:56.882912Z",
     "start_time": "2019-02-14T08:12:56.876023Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T08:13:35.469942Z",
     "start_time": "2019-02-14T08:12:57.275034Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(path + 'train_v3.csv')\n",
    "test = pd.read_csv(path + 'test_v3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T04:50:40.432745Z",
     "start_time": "2019-02-08T04:50:39.706686Z"
    }
   },
   "outputs": [],
   "source": [
    "train_neg = train[train.target < 0]\n",
    "train_neg_not = train[train.target >= 0]\n",
    "\n",
    "train_pos = train[train.target >= 0]\n",
    "train_pos_not = train[train.target < 0]\n",
    "\n",
    "train_without_outliers = train[train.outliers == 0]\n",
    "train_outliers = train[train.outliers != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T04:50:40.441720Z",
     "start_time": "2019-02-08T04:50:40.434740Z"
    }
   },
   "outputs": [],
   "source": [
    "templete = train.card_id.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제거할 피처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:09:57.500431Z",
     "start_time": "2019-02-07T15:09:57.496442Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATS_EXCLUDED = ['first_active', 'card_id', 'target', 'outliers',\n",
    "                  'hist_purchase_date_max', 'hist_purchase_date_min', \n",
    "                  'new_purchase_date_max', 'new_purchase_date_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:09:58.164172Z",
     "start_time": "2019-02-07T15:09:58.159278Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         \"random_state\": 4590}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:36:41.320875Z",
     "start_time": "2019-02-07T15:25:57.106158Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.65093\tvalid_1's rmse: 3.71886\n",
      "[200]\ttraining's rmse: 3.56623\tvalid_1's rmse: 3.68747\n",
      "[300]\ttraining's rmse: 3.50999\tvalid_1's rmse: 3.67526\n",
      "[400]\ttraining's rmse: 3.4668\tvalid_1's rmse: 3.66859\n",
      "[500]\ttraining's rmse: 3.4312\tvalid_1's rmse: 3.66532\n",
      "[600]\ttraining's rmse: 3.40089\tvalid_1's rmse: 3.66367\n",
      "[700]\ttraining's rmse: 3.37362\tvalid_1's rmse: 3.66194\n",
      "[800]\ttraining's rmse: 3.35011\tvalid_1's rmse: 3.66162\n",
      "[900]\ttraining's rmse: 3.32715\tvalid_1's rmse: 3.66089\n",
      "[1000]\ttraining's rmse: 3.30606\tvalid_1's rmse: 3.66029\n",
      "[1100]\ttraining's rmse: 3.28622\tvalid_1's rmse: 3.65951\n",
      "[1200]\ttraining's rmse: 3.26596\tvalid_1's rmse: 3.65943\n",
      "[1300]\ttraining's rmse: 3.24718\tvalid_1's rmse: 3.6596\n",
      "[1400]\ttraining's rmse: 3.22819\tvalid_1's rmse: 3.65974\n",
      "Early stopping, best iteration is:\n",
      "[1248]\ttraining's rmse: 3.25659\tvalid_1's rmse: 3.65928\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.64903\tvalid_1's rmse: 3.72636\n",
      "[200]\ttraining's rmse: 3.56211\tvalid_1's rmse: 3.69838\n",
      "[300]\ttraining's rmse: 3.50645\tvalid_1's rmse: 3.68524\n",
      "[400]\ttraining's rmse: 3.46402\tvalid_1's rmse: 3.67693\n",
      "[500]\ttraining's rmse: 3.42858\tvalid_1's rmse: 3.67162\n",
      "[600]\ttraining's rmse: 3.39855\tvalid_1's rmse: 3.66882\n",
      "[700]\ttraining's rmse: 3.37194\tvalid_1's rmse: 3.66733\n",
      "[800]\ttraining's rmse: 3.3471\tvalid_1's rmse: 3.66598\n",
      "[900]\ttraining's rmse: 3.32463\tvalid_1's rmse: 3.66463\n",
      "[1000]\ttraining's rmse: 3.30305\tvalid_1's rmse: 3.66363\n",
      "[1100]\ttraining's rmse: 3.28286\tvalid_1's rmse: 3.66316\n",
      "[1200]\ttraining's rmse: 3.26385\tvalid_1's rmse: 3.66275\n",
      "[1300]\ttraining's rmse: 3.24594\tvalid_1's rmse: 3.66245\n",
      "[1400]\ttraining's rmse: 3.22743\tvalid_1's rmse: 3.66212\n",
      "[1500]\ttraining's rmse: 3.21044\tvalid_1's rmse: 3.66231\n",
      "[1600]\ttraining's rmse: 3.19421\tvalid_1's rmse: 3.6621\n",
      "[1700]\ttraining's rmse: 3.17821\tvalid_1's rmse: 3.66198\n",
      "[1800]\ttraining's rmse: 3.16288\tvalid_1's rmse: 3.66218\n",
      "[1900]\ttraining's rmse: 3.14701\tvalid_1's rmse: 3.66217\n",
      "Early stopping, best iteration is:\n",
      "[1713]\ttraining's rmse: 3.17619\tvalid_1's rmse: 3.66182\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.65378\tvalid_1's rmse: 3.70907\n",
      "[200]\ttraining's rmse: 3.56812\tvalid_1's rmse: 3.67638\n",
      "[300]\ttraining's rmse: 3.51389\tvalid_1's rmse: 3.66229\n",
      "[400]\ttraining's rmse: 3.47142\tvalid_1's rmse: 3.65373\n",
      "[500]\ttraining's rmse: 3.4357\tvalid_1's rmse: 3.64929\n",
      "[600]\ttraining's rmse: 3.40534\tvalid_1's rmse: 3.64578\n",
      "[700]\ttraining's rmse: 3.37769\tvalid_1's rmse: 3.64404\n",
      "[800]\ttraining's rmse: 3.35216\tvalid_1's rmse: 3.64318\n",
      "[900]\ttraining's rmse: 3.32834\tvalid_1's rmse: 3.64229\n",
      "[1000]\ttraining's rmse: 3.30627\tvalid_1's rmse: 3.64207\n",
      "[1100]\ttraining's rmse: 3.28565\tvalid_1's rmse: 3.64173\n",
      "[1200]\ttraining's rmse: 3.2656\tvalid_1's rmse: 3.64131\n",
      "[1300]\ttraining's rmse: 3.24657\tvalid_1's rmse: 3.64132\n",
      "[1400]\ttraining's rmse: 3.22843\tvalid_1's rmse: 3.64161\n",
      "Early stopping, best iteration is:\n",
      "[1211]\ttraining's rmse: 3.26374\tvalid_1's rmse: 3.64108\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.65546\tvalid_1's rmse: 3.71178\n",
      "[200]\ttraining's rmse: 3.57023\tvalid_1's rmse: 3.67897\n",
      "[300]\ttraining's rmse: 3.51496\tvalid_1's rmse: 3.6665\n",
      "[400]\ttraining's rmse: 3.47169\tvalid_1's rmse: 3.66018\n",
      "[500]\ttraining's rmse: 3.43661\tvalid_1's rmse: 3.65501\n",
      "[600]\ttraining's rmse: 3.4057\tvalid_1's rmse: 3.65185\n",
      "[700]\ttraining's rmse: 3.37886\tvalid_1's rmse: 3.64945\n",
      "[800]\ttraining's rmse: 3.35435\tvalid_1's rmse: 3.64802\n",
      "[900]\ttraining's rmse: 3.3322\tvalid_1's rmse: 3.64687\n",
      "[1000]\ttraining's rmse: 3.31083\tvalid_1's rmse: 3.64592\n",
      "[1100]\ttraining's rmse: 3.2907\tvalid_1's rmse: 3.64532\n",
      "[1200]\ttraining's rmse: 3.27207\tvalid_1's rmse: 3.64521\n",
      "[1300]\ttraining's rmse: 3.25335\tvalid_1's rmse: 3.64506\n",
      "[1400]\ttraining's rmse: 3.23543\tvalid_1's rmse: 3.64522\n",
      "Early stopping, best iteration is:\n",
      "[1229]\ttraining's rmse: 3.26627\tvalid_1's rmse: 3.64478\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.65146\tvalid_1's rmse: 3.72608\n",
      "[200]\ttraining's rmse: 3.56641\tvalid_1's rmse: 3.69471\n",
      "[300]\ttraining's rmse: 3.51161\tvalid_1's rmse: 3.68044\n",
      "[400]\ttraining's rmse: 3.46915\tvalid_1's rmse: 3.67269\n",
      "[500]\ttraining's rmse: 3.43383\tvalid_1's rmse: 3.66648\n",
      "[600]\ttraining's rmse: 3.40378\tvalid_1's rmse: 3.66254\n",
      "[700]\ttraining's rmse: 3.37728\tvalid_1's rmse: 3.65942\n",
      "[800]\ttraining's rmse: 3.35316\tvalid_1's rmse: 3.6581\n",
      "[900]\ttraining's rmse: 3.33073\tvalid_1's rmse: 3.65721\n",
      "[1000]\ttraining's rmse: 3.30948\tvalid_1's rmse: 3.65595\n",
      "[1100]\ttraining's rmse: 3.29015\tvalid_1's rmse: 3.65544\n",
      "[1200]\ttraining's rmse: 3.27092\tvalid_1's rmse: 3.65552\n",
      "[1300]\ttraining's rmse: 3.25194\tvalid_1's rmse: 3.65502\n",
      "[1400]\ttraining's rmse: 3.23401\tvalid_1's rmse: 3.65429\n",
      "[1500]\ttraining's rmse: 3.21816\tvalid_1's rmse: 3.65422\n",
      "[1600]\ttraining's rmse: 3.20167\tvalid_1's rmse: 3.65354\n",
      "[1700]\ttraining's rmse: 3.18553\tvalid_1's rmse: 3.65301\n",
      "[1800]\ttraining's rmse: 3.16987\tvalid_1's rmse: 3.65265\n",
      "[1900]\ttraining's rmse: 3.15447\tvalid_1's rmse: 3.65216\n",
      "[2000]\ttraining's rmse: 3.13881\tvalid_1's rmse: 3.65147\n",
      "[2100]\ttraining's rmse: 3.12357\tvalid_1's rmse: 3.65111\n",
      "[2200]\ttraining's rmse: 3.10937\tvalid_1's rmse: 3.65152\n",
      "Early stopping, best iteration is:\n",
      "[2087]\ttraining's rmse: 3.12531\tvalid_1's rmse: 3.65105\n",
      "CV score: 3.65161 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "train_columns = [f for f in train.columns if f not in FEATS_EXCLUDED]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train['outliers'].values)):    \n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][train_columns], label=train.iloc[trn_idx]['target'])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][train_columns], label=train.iloc[val_idx]['target'])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof_lgb[val_idx] = clf.predict(train.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(test[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"Feature\"] = train_columns\n",
    "    fold_importance[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_ + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(train.target.values, oof_lgb)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:40:12.351392Z",
     "start_time": "2019-02-07T15:40:11.826410Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'card_id':train.card_id, 'target':oof_lgb}).to_csv('./data_modeling/base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:19:20.905208Z",
     "start_time": "2019-02-07T15:14:37.328415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 4.37729\tvalid_1's rmse: 4.48336\n",
      "[200]\ttraining's rmse: 4.20132\tvalid_1's rmse: 4.41881\n",
      "[300]\ttraining's rmse: 4.09083\tvalid_1's rmse: 4.40427\n",
      "[400]\ttraining's rmse: 4.01414\tvalid_1's rmse: 4.39889\n",
      "[500]\ttraining's rmse: 3.95348\tvalid_1's rmse: 4.39641\n",
      "[600]\ttraining's rmse: 3.90102\tvalid_1's rmse: 4.39408\n",
      "[700]\ttraining's rmse: 3.85493\tvalid_1's rmse: 4.3923\n",
      "[800]\ttraining's rmse: 3.81237\tvalid_1's rmse: 4.39143\n",
      "[900]\ttraining's rmse: 3.77291\tvalid_1's rmse: 4.39225\n",
      "Early stopping, best iteration is:\n",
      "[793]\ttraining's rmse: 3.81512\tvalid_1's rmse: 4.39137\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 4.37377\tvalid_1's rmse: 4.50167\n",
      "[200]\ttraining's rmse: 4.19686\tvalid_1's rmse: 4.42827\n",
      "[300]\ttraining's rmse: 4.08735\tvalid_1's rmse: 4.40599\n",
      "[400]\ttraining's rmse: 4.01152\tvalid_1's rmse: 4.39848\n",
      "[500]\ttraining's rmse: 3.95058\tvalid_1's rmse: 4.39508\n",
      "[600]\ttraining's rmse: 3.89862\tvalid_1's rmse: 4.39253\n",
      "[700]\ttraining's rmse: 3.852\tvalid_1's rmse: 4.39194\n",
      "[800]\ttraining's rmse: 3.80843\tvalid_1's rmse: 4.3909\n",
      "[900]\ttraining's rmse: 3.76913\tvalid_1's rmse: 4.3913\n",
      "[1000]\ttraining's rmse: 3.73063\tvalid_1's rmse: 4.39062\n",
      "[1100]\ttraining's rmse: 3.69453\tvalid_1's rmse: 4.38986\n",
      "[1200]\ttraining's rmse: 3.66075\tvalid_1's rmse: 4.39035\n",
      "Early stopping, best iteration is:\n",
      "[1069]\ttraining's rmse: 3.70487\tvalid_1's rmse: 4.38963\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 4.37435\tvalid_1's rmse: 4.50556\n",
      "[200]\ttraining's rmse: 4.19634\tvalid_1's rmse: 4.44524\n",
      "[300]\ttraining's rmse: 4.08383\tvalid_1's rmse: 4.42929\n",
      "[400]\ttraining's rmse: 4.00795\tvalid_1's rmse: 4.42228\n",
      "[500]\ttraining's rmse: 3.94994\tvalid_1's rmse: 4.41997\n",
      "[600]\ttraining's rmse: 3.89782\tvalid_1's rmse: 4.41892\n",
      "[700]\ttraining's rmse: 3.85384\tvalid_1's rmse: 4.41796\n",
      "[800]\ttraining's rmse: 3.81086\tvalid_1's rmse: 4.41719\n",
      "[900]\ttraining's rmse: 3.77171\tvalid_1's rmse: 4.41685\n",
      "[1000]\ttraining's rmse: 3.73387\tvalid_1's rmse: 4.41595\n",
      "[1100]\ttraining's rmse: 3.69803\tvalid_1's rmse: 4.41546\n",
      "[1200]\ttraining's rmse: 3.66442\tvalid_1's rmse: 4.41504\n",
      "[1300]\ttraining's rmse: 3.63136\tvalid_1's rmse: 4.41603\n",
      "Early stopping, best iteration is:\n",
      "[1169]\ttraining's rmse: 3.67516\tvalid_1's rmse: 4.41458\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 4.37993\tvalid_1's rmse: 4.48797\n",
      "[200]\ttraining's rmse: 4.20509\tvalid_1's rmse: 4.42174\n",
      "[300]\ttraining's rmse: 4.09855\tvalid_1's rmse: 4.40003\n",
      "[400]\ttraining's rmse: 4.02125\tvalid_1's rmse: 4.39178\n",
      "[500]\ttraining's rmse: 3.96048\tvalid_1's rmse: 4.38907\n",
      "[600]\ttraining's rmse: 3.90764\tvalid_1's rmse: 4.38711\n",
      "[700]\ttraining's rmse: 3.85984\tvalid_1's rmse: 4.38653\n",
      "[800]\ttraining's rmse: 3.81735\tvalid_1's rmse: 4.3865\n",
      "[900]\ttraining's rmse: 3.7767\tvalid_1's rmse: 4.38676\n",
      "Early stopping, best iteration is:\n",
      "[778]\ttraining's rmse: 3.82609\tvalid_1's rmse: 4.38577\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 4.37347\tvalid_1's rmse: 4.5038\n",
      "[200]\ttraining's rmse: 4.19783\tvalid_1's rmse: 4.44364\n",
      "[300]\ttraining's rmse: 4.08905\tvalid_1's rmse: 4.42708\n",
      "[400]\ttraining's rmse: 4.01395\tvalid_1's rmse: 4.42089\n",
      "[500]\ttraining's rmse: 3.95689\tvalid_1's rmse: 4.41981\n",
      "[600]\ttraining's rmse: 3.90525\tvalid_1's rmse: 4.41852\n",
      "[700]\ttraining's rmse: 3.85887\tvalid_1's rmse: 4.41798\n",
      "[800]\ttraining's rmse: 3.81523\tvalid_1's rmse: 4.41643\n",
      "[900]\ttraining's rmse: 3.77643\tvalid_1's rmse: 4.41744\n",
      "Early stopping, best iteration is:\n",
      "[755]\ttraining's rmse: 3.8341\tvalid_1's rmse: 4.41627\n",
      "CV score: 4.39954 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof_lgb_neg = np.zeros(len(train_neg))\n",
    "oof_lgb_neg_not = np.zeros(len(train_neg_not))\n",
    "predictions_lgb_neg = np.zeros(len(test))\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "train_columns = [f for f in train_neg.columns if f not in FEATS_EXCLUDED]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_neg, train_neg['outliers'].values)):    \n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_neg.iloc[trn_idx][train_columns], label=train_neg.iloc[trn_idx]['target'])\n",
    "    val_data = lgb.Dataset(train_neg.iloc[val_idx][train_columns], label=train_neg.iloc[val_idx]['target'])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof_lgb_neg[val_idx] = clf.predict(train_neg.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    oof_lgb_neg_not += clf.predict(train_neg_not[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    predictions_lgb_neg += clf.predict(test[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"Feature\"] = train_columns\n",
    "    fold_importance[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_ + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(train_neg.target.values, oof_lgb_neg)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:40:33.818435Z",
     "start_time": "2019-02-07T15:40:33.155320Z"
    }
   },
   "outputs": [],
   "source": [
    "templete.merge(pd.DataFrame({'card_id':train_neg_not.card_id, 'target': oof_lgb_neg_not}).append(pd.DataFrame({'card_id':train_neg.card_id, 'target': oof_lgb_neg})), how='left').to_csv('./data_modeling/neg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:56:00.423841Z",
     "start_time": "2019-02-07T15:46:39.718182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.09163\tvalid_1's rmse: 1.12028\n",
      "[200]\ttraining's rmse: 1.05349\tvalid_1's rmse: 1.0887\n",
      "[300]\ttraining's rmse: 1.03405\tvalid_1's rmse: 1.07696\n",
      "[400]\ttraining's rmse: 1.02055\tvalid_1's rmse: 1.07118\n",
      "[500]\ttraining's rmse: 1.00977\tvalid_1's rmse: 1.06757\n",
      "[600]\ttraining's rmse: 1.00037\tvalid_1's rmse: 1.06554\n",
      "[700]\ttraining's rmse: 0.991945\tvalid_1's rmse: 1.06445\n",
      "[800]\ttraining's rmse: 0.984353\tvalid_1's rmse: 1.06328\n",
      "[900]\ttraining's rmse: 0.977305\tvalid_1's rmse: 1.06244\n",
      "[1000]\ttraining's rmse: 0.970732\tvalid_1's rmse: 1.06198\n",
      "[1100]\ttraining's rmse: 0.964622\tvalid_1's rmse: 1.06162\n",
      "[1200]\ttraining's rmse: 0.958608\tvalid_1's rmse: 1.06127\n",
      "[1300]\ttraining's rmse: 0.9528\tvalid_1's rmse: 1.06094\n",
      "[1400]\ttraining's rmse: 0.947226\tvalid_1's rmse: 1.06065\n",
      "[1500]\ttraining's rmse: 0.941975\tvalid_1's rmse: 1.0606\n",
      "[1600]\ttraining's rmse: 0.936464\tvalid_1's rmse: 1.06038\n",
      "[1700]\ttraining's rmse: 0.931153\tvalid_1's rmse: 1.0602\n",
      "[1800]\ttraining's rmse: 0.925959\tvalid_1's rmse: 1.06006\n",
      "[1900]\ttraining's rmse: 0.920989\tvalid_1's rmse: 1.05996\n",
      "[2000]\ttraining's rmse: 0.916046\tvalid_1's rmse: 1.05977\n",
      "[2100]\ttraining's rmse: 0.911188\tvalid_1's rmse: 1.0597\n",
      "[2200]\ttraining's rmse: 0.906453\tvalid_1's rmse: 1.0597\n",
      "[2300]\ttraining's rmse: 0.901634\tvalid_1's rmse: 1.05976\n",
      "Early stopping, best iteration is:\n",
      "[2145]\ttraining's rmse: 0.909072\tvalid_1's rmse: 1.05963\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.09754\tvalid_1's rmse: 1.09493\n",
      "[200]\ttraining's rmse: 1.05901\tvalid_1's rmse: 1.0654\n",
      "[300]\ttraining's rmse: 1.03919\tvalid_1's rmse: 1.05438\n",
      "[400]\ttraining's rmse: 1.02534\tvalid_1's rmse: 1.04864\n",
      "[500]\ttraining's rmse: 1.01416\tvalid_1's rmse: 1.04544\n",
      "[600]\ttraining's rmse: 1.00452\tvalid_1's rmse: 1.04325\n",
      "[700]\ttraining's rmse: 0.996102\tvalid_1's rmse: 1.04207\n",
      "[800]\ttraining's rmse: 0.988378\tvalid_1's rmse: 1.04119\n",
      "[900]\ttraining's rmse: 0.981211\tvalid_1's rmse: 1.04062\n",
      "[1000]\ttraining's rmse: 0.974374\tvalid_1's rmse: 1.04006\n",
      "[1100]\ttraining's rmse: 0.968183\tvalid_1's rmse: 1.03975\n",
      "[1200]\ttraining's rmse: 0.961936\tvalid_1's rmse: 1.03934\n",
      "[1300]\ttraining's rmse: 0.956164\tvalid_1's rmse: 1.0391\n",
      "[1400]\ttraining's rmse: 0.950424\tvalid_1's rmse: 1.03898\n",
      "[1500]\ttraining's rmse: 0.944995\tvalid_1's rmse: 1.03868\n",
      "[1600]\ttraining's rmse: 0.939454\tvalid_1's rmse: 1.03861\n",
      "[1700]\ttraining's rmse: 0.934263\tvalid_1's rmse: 1.03853\n",
      "[1800]\ttraining's rmse: 0.929024\tvalid_1's rmse: 1.03848\n",
      "[1900]\ttraining's rmse: 0.923971\tvalid_1's rmse: 1.03845\n",
      "[2000]\ttraining's rmse: 0.919061\tvalid_1's rmse: 1.03834\n",
      "[2100]\ttraining's rmse: 0.914119\tvalid_1's rmse: 1.03833\n",
      "[2200]\ttraining's rmse: 0.909265\tvalid_1's rmse: 1.0384\n",
      "Early stopping, best iteration is:\n",
      "[2033]\ttraining's rmse: 0.917434\tvalid_1's rmse: 1.03832\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.09437\tvalid_1's rmse: 1.1038\n",
      "[200]\ttraining's rmse: 1.05544\tvalid_1's rmse: 1.07561\n",
      "[300]\ttraining's rmse: 1.03553\tvalid_1's rmse: 1.06586\n",
      "[400]\ttraining's rmse: 1.02177\tvalid_1's rmse: 1.06162\n",
      "[500]\ttraining's rmse: 1.01063\tvalid_1's rmse: 1.05891\n",
      "[600]\ttraining's rmse: 1.00099\tvalid_1's rmse: 1.05697\n",
      "[700]\ttraining's rmse: 0.9925\tvalid_1's rmse: 1.05576\n",
      "[800]\ttraining's rmse: 0.984728\tvalid_1's rmse: 1.05496\n",
      "[900]\ttraining's rmse: 0.977475\tvalid_1's rmse: 1.05441\n",
      "[1000]\ttraining's rmse: 0.970603\tvalid_1's rmse: 1.05399\n",
      "[1100]\ttraining's rmse: 0.964276\tvalid_1's rmse: 1.0537\n",
      "[1200]\ttraining's rmse: 0.958017\tvalid_1's rmse: 1.05332\n",
      "[1300]\ttraining's rmse: 0.952074\tvalid_1's rmse: 1.05298\n",
      "[1400]\ttraining's rmse: 0.946303\tvalid_1's rmse: 1.05283\n",
      "[1500]\ttraining's rmse: 0.940588\tvalid_1's rmse: 1.05273\n",
      "[1600]\ttraining's rmse: 0.935077\tvalid_1's rmse: 1.0526\n",
      "[1700]\ttraining's rmse: 0.929724\tvalid_1's rmse: 1.05246\n",
      "[1800]\ttraining's rmse: 0.924453\tvalid_1's rmse: 1.05249\n",
      "[1900]\ttraining's rmse: 0.919307\tvalid_1's rmse: 1.05248\n",
      "Early stopping, best iteration is:\n",
      "[1735]\ttraining's rmse: 0.927915\tvalid_1's rmse: 1.05239\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.08908\tvalid_1's rmse: 1.12809\n",
      "[200]\ttraining's rmse: 1.05014\tvalid_1's rmse: 1.09896\n",
      "[300]\ttraining's rmse: 1.03018\tvalid_1's rmse: 1.08832\n",
      "[400]\ttraining's rmse: 1.01649\tvalid_1's rmse: 1.08359\n",
      "[500]\ttraining's rmse: 1.00522\tvalid_1's rmse: 1.08054\n",
      "[600]\ttraining's rmse: 0.995673\tvalid_1's rmse: 1.07868\n",
      "[700]\ttraining's rmse: 0.987246\tvalid_1's rmse: 1.07751\n",
      "[800]\ttraining's rmse: 0.979574\tvalid_1's rmse: 1.07679\n",
      "[900]\ttraining's rmse: 0.972377\tvalid_1's rmse: 1.07623\n",
      "[1000]\ttraining's rmse: 0.965659\tvalid_1's rmse: 1.0759\n",
      "[1100]\ttraining's rmse: 0.959386\tvalid_1's rmse: 1.07572\n",
      "[1200]\ttraining's rmse: 0.953318\tvalid_1's rmse: 1.07555\n",
      "[1300]\ttraining's rmse: 0.947382\tvalid_1's rmse: 1.07547\n",
      "[1400]\ttraining's rmse: 0.941721\tvalid_1's rmse: 1.07546\n",
      "[1500]\ttraining's rmse: 0.936307\tvalid_1's rmse: 1.07534\n",
      "[1600]\ttraining's rmse: 0.930973\tvalid_1's rmse: 1.07526\n",
      "[1700]\ttraining's rmse: 0.925746\tvalid_1's rmse: 1.07518\n",
      "[1800]\ttraining's rmse: 0.920672\tvalid_1's rmse: 1.07517\n",
      "[1900]\ttraining's rmse: 0.915672\tvalid_1's rmse: 1.07516\n",
      "[2000]\ttraining's rmse: 0.910599\tvalid_1's rmse: 1.07504\n",
      "[2100]\ttraining's rmse: 0.905666\tvalid_1's rmse: 1.07511\n",
      "Early stopping, best iteration is:\n",
      "[1984]\ttraining's rmse: 0.911364\tvalid_1's rmse: 1.07498\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.10119\tvalid_1's rmse: 1.07645\n",
      "[200]\ttraining's rmse: 1.06192\tvalid_1's rmse: 1.04842\n",
      "[300]\ttraining's rmse: 1.04197\tvalid_1's rmse: 1.03818\n",
      "[400]\ttraining's rmse: 1.02819\tvalid_1's rmse: 1.03345\n",
      "[500]\ttraining's rmse: 1.01697\tvalid_1's rmse: 1.03051\n",
      "[600]\ttraining's rmse: 1.00732\tvalid_1's rmse: 1.02848\n",
      "[700]\ttraining's rmse: 0.998847\tvalid_1's rmse: 1.0272\n",
      "[800]\ttraining's rmse: 0.991111\tvalid_1's rmse: 1.0264\n",
      "[900]\ttraining's rmse: 0.983879\tvalid_1's rmse: 1.02572\n",
      "[1000]\ttraining's rmse: 0.976983\tvalid_1's rmse: 1.02536\n",
      "[1100]\ttraining's rmse: 0.970436\tvalid_1's rmse: 1.02499\n",
      "[1200]\ttraining's rmse: 0.964287\tvalid_1's rmse: 1.0248\n",
      "[1300]\ttraining's rmse: 0.95818\tvalid_1's rmse: 1.02447\n",
      "[1400]\ttraining's rmse: 0.952417\tvalid_1's rmse: 1.02441\n",
      "[1500]\ttraining's rmse: 0.94687\tvalid_1's rmse: 1.02428\n",
      "[1600]\ttraining's rmse: 0.941462\tvalid_1's rmse: 1.02428\n",
      "[1700]\ttraining's rmse: 0.93601\tvalid_1's rmse: 1.0242\n",
      "Early stopping, best iteration is:\n",
      "[1554]\ttraining's rmse: 0.943914\tvalid_1's rmse: 1.02418\n",
      "CV score: 1.05005 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof_lgb_pos = np.zeros(len(train_pos))\n",
    "oof_lgb_pos_not = np.zeros(len(train_pos_not))\n",
    "predictions_lgb_pos = np.zeros(len(test))\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "train_columns = [f for f in train_pos.columns if f not in FEATS_EXCLUDED]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_pos, train_pos['outliers'].values)):    \n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_pos.iloc[trn_idx][train_columns], label=train_pos.iloc[trn_idx]['target'])\n",
    "    val_data = lgb.Dataset(train_pos.iloc[val_idx][train_columns], label=train_pos.iloc[val_idx]['target'])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof_lgb_pos[val_idx] = clf.predict(train_pos.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    oof_lgb_pos_not += clf.predict(train_pos_not[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    predictions_lgb_pos += clf.predict(test[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"Feature\"] = train_columns\n",
    "    fold_importance[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_ + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(train_pos.target.values, oof_lgb_pos)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:56:01.145160Z",
     "start_time": "2019-02-07T15:56:00.425837Z"
    }
   },
   "outputs": [],
   "source": [
    "templete.merge(pd.DataFrame({'card_id':train_pos_not.card_id, 'target': oof_lgb_pos_not}).append(pd.DataFrame({'card_id':train_pos.card_id, 'target': oof_lgb_pos})), how='left').to_csv('./data_modeling/pos.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T16:13:06.131951Z",
     "start_time": "2019-02-07T15:56:01.145160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.60508\tvalid_1's rmse: 1.61676\n",
      "[200]\ttraining's rmse: 1.57258\tvalid_1's rmse: 1.58947\n",
      "[300]\ttraining's rmse: 1.5569\tvalid_1's rmse: 1.57843\n",
      "[400]\ttraining's rmse: 1.54652\tvalid_1's rmse: 1.57278\n",
      "[500]\ttraining's rmse: 1.53831\tvalid_1's rmse: 1.56901\n",
      "[600]\ttraining's rmse: 1.53133\tvalid_1's rmse: 1.56669\n",
      "[700]\ttraining's rmse: 1.52511\tvalid_1's rmse: 1.56515\n",
      "[800]\ttraining's rmse: 1.51955\tvalid_1's rmse: 1.56427\n",
      "[900]\ttraining's rmse: 1.51443\tvalid_1's rmse: 1.5636\n",
      "[1000]\ttraining's rmse: 1.50958\tvalid_1's rmse: 1.56307\n",
      "[1100]\ttraining's rmse: 1.50494\tvalid_1's rmse: 1.56258\n",
      "[1200]\ttraining's rmse: 1.50054\tvalid_1's rmse: 1.56232\n",
      "[1300]\ttraining's rmse: 1.49619\tvalid_1's rmse: 1.56206\n",
      "[1400]\ttraining's rmse: 1.492\tvalid_1's rmse: 1.5618\n",
      "[1500]\ttraining's rmse: 1.4879\tvalid_1's rmse: 1.56166\n",
      "[1600]\ttraining's rmse: 1.48388\tvalid_1's rmse: 1.56144\n",
      "[1700]\ttraining's rmse: 1.47992\tvalid_1's rmse: 1.56131\n",
      "[1800]\ttraining's rmse: 1.47591\tvalid_1's rmse: 1.56122\n",
      "[1900]\ttraining's rmse: 1.47199\tvalid_1's rmse: 1.5611\n",
      "[2000]\ttraining's rmse: 1.46814\tvalid_1's rmse: 1.56108\n",
      "[2100]\ttraining's rmse: 1.46424\tvalid_1's rmse: 1.56107\n",
      "[2200]\ttraining's rmse: 1.46048\tvalid_1's rmse: 1.56106\n",
      "Early stopping, best iteration is:\n",
      "[2009]\ttraining's rmse: 1.46783\tvalid_1's rmse: 1.56104\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.60584\tvalid_1's rmse: 1.61461\n",
      "[200]\ttraining's rmse: 1.57339\tvalid_1's rmse: 1.58669\n",
      "[300]\ttraining's rmse: 1.55754\tvalid_1's rmse: 1.5757\n",
      "[400]\ttraining's rmse: 1.54694\tvalid_1's rmse: 1.57008\n",
      "[500]\ttraining's rmse: 1.53863\tvalid_1's rmse: 1.56661\n",
      "[600]\ttraining's rmse: 1.53148\tvalid_1's rmse: 1.56436\n",
      "[700]\ttraining's rmse: 1.52518\tvalid_1's rmse: 1.56301\n",
      "[800]\ttraining's rmse: 1.51953\tvalid_1's rmse: 1.56204\n",
      "[900]\ttraining's rmse: 1.51431\tvalid_1's rmse: 1.56134\n",
      "[1000]\ttraining's rmse: 1.50943\tvalid_1's rmse: 1.56088\n",
      "[1100]\ttraining's rmse: 1.50482\tvalid_1's rmse: 1.56052\n",
      "[1200]\ttraining's rmse: 1.50026\tvalid_1's rmse: 1.56021\n",
      "[1300]\ttraining's rmse: 1.49585\tvalid_1's rmse: 1.55998\n",
      "[1400]\ttraining's rmse: 1.49155\tvalid_1's rmse: 1.5597\n",
      "[1500]\ttraining's rmse: 1.48751\tvalid_1's rmse: 1.5596\n",
      "[1600]\ttraining's rmse: 1.48351\tvalid_1's rmse: 1.55945\n",
      "[1700]\ttraining's rmse: 1.47957\tvalid_1's rmse: 1.55936\n",
      "[1800]\ttraining's rmse: 1.47572\tvalid_1's rmse: 1.55924\n",
      "[1900]\ttraining's rmse: 1.47172\tvalid_1's rmse: 1.55916\n",
      "[2000]\ttraining's rmse: 1.46794\tvalid_1's rmse: 1.55911\n",
      "[2100]\ttraining's rmse: 1.46406\tvalid_1's rmse: 1.55906\n",
      "[2200]\ttraining's rmse: 1.4604\tvalid_1's rmse: 1.55904\n",
      "[2300]\ttraining's rmse: 1.45669\tvalid_1's rmse: 1.55894\n",
      "[2400]\ttraining's rmse: 1.453\tvalid_1's rmse: 1.5589\n",
      "[2500]\ttraining's rmse: 1.44937\tvalid_1's rmse: 1.55896\n",
      "Early stopping, best iteration is:\n",
      "[2340]\ttraining's rmse: 1.45518\tvalid_1's rmse: 1.55886\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.61072\tvalid_1's rmse: 1.59327\n",
      "[200]\ttraining's rmse: 1.57845\tvalid_1's rmse: 1.56552\n",
      "[300]\ttraining's rmse: 1.56276\tvalid_1's rmse: 1.55478\n",
      "[400]\ttraining's rmse: 1.55234\tvalid_1's rmse: 1.54917\n",
      "[500]\ttraining's rmse: 1.54409\tvalid_1's rmse: 1.54587\n",
      "[600]\ttraining's rmse: 1.53698\tvalid_1's rmse: 1.54351\n",
      "[700]\ttraining's rmse: 1.53075\tvalid_1's rmse: 1.54193\n",
      "[800]\ttraining's rmse: 1.52514\tvalid_1's rmse: 1.54095\n",
      "[900]\ttraining's rmse: 1.51991\tvalid_1's rmse: 1.54028\n",
      "[1000]\ttraining's rmse: 1.51496\tvalid_1's rmse: 1.5397\n",
      "[1100]\ttraining's rmse: 1.5103\tvalid_1's rmse: 1.53929\n",
      "[1200]\ttraining's rmse: 1.50583\tvalid_1's rmse: 1.53903\n",
      "[1300]\ttraining's rmse: 1.50156\tvalid_1's rmse: 1.53884\n",
      "[1400]\ttraining's rmse: 1.49735\tvalid_1's rmse: 1.53867\n",
      "[1500]\ttraining's rmse: 1.49316\tvalid_1's rmse: 1.53842\n",
      "[1600]\ttraining's rmse: 1.48908\tvalid_1's rmse: 1.53824\n",
      "[1700]\ttraining's rmse: 1.48513\tvalid_1's rmse: 1.5382\n",
      "[1800]\ttraining's rmse: 1.48117\tvalid_1's rmse: 1.53814\n",
      "[1900]\ttraining's rmse: 1.47719\tvalid_1's rmse: 1.53812\n",
      "[2000]\ttraining's rmse: 1.47332\tvalid_1's rmse: 1.53811\n",
      "[2100]\ttraining's rmse: 1.46949\tvalid_1's rmse: 1.53796\n",
      "[2200]\ttraining's rmse: 1.46578\tvalid_1's rmse: 1.53788\n",
      "[2300]\ttraining's rmse: 1.46198\tvalid_1's rmse: 1.53771\n",
      "[2400]\ttraining's rmse: 1.45823\tvalid_1's rmse: 1.53766\n",
      "[2500]\ttraining's rmse: 1.45458\tvalid_1's rmse: 1.53766\n",
      "[2600]\ttraining's rmse: 1.45098\tvalid_1's rmse: 1.53763\n",
      "[2700]\ttraining's rmse: 1.44753\tvalid_1's rmse: 1.53766\n",
      "[2800]\ttraining's rmse: 1.44397\tvalid_1's rmse: 1.53755\n",
      "[2900]\ttraining's rmse: 1.44049\tvalid_1's rmse: 1.53756\n",
      "[3000]\ttraining's rmse: 1.43708\tvalid_1's rmse: 1.53756\n",
      "Early stopping, best iteration is:\n",
      "[2827]\ttraining's rmse: 1.44299\tvalid_1's rmse: 1.53752\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.60593\tvalid_1's rmse: 1.61355\n",
      "[200]\ttraining's rmse: 1.57368\tvalid_1's rmse: 1.58562\n",
      "[300]\ttraining's rmse: 1.55802\tvalid_1's rmse: 1.57458\n",
      "[400]\ttraining's rmse: 1.54765\tvalid_1's rmse: 1.569\n",
      "[500]\ttraining's rmse: 1.53949\tvalid_1's rmse: 1.56552\n",
      "[600]\ttraining's rmse: 1.53253\tvalid_1's rmse: 1.56334\n",
      "[700]\ttraining's rmse: 1.52628\tvalid_1's rmse: 1.56195\n",
      "[800]\ttraining's rmse: 1.52065\tvalid_1's rmse: 1.56101\n",
      "[900]\ttraining's rmse: 1.51555\tvalid_1's rmse: 1.56044\n",
      "[1000]\ttraining's rmse: 1.51064\tvalid_1's rmse: 1.55996\n",
      "[1100]\ttraining's rmse: 1.50611\tvalid_1's rmse: 1.55967\n",
      "[1200]\ttraining's rmse: 1.50167\tvalid_1's rmse: 1.55953\n",
      "[1300]\ttraining's rmse: 1.49734\tvalid_1's rmse: 1.55922\n",
      "[1400]\ttraining's rmse: 1.49322\tvalid_1's rmse: 1.55908\n",
      "[1500]\ttraining's rmse: 1.48899\tvalid_1's rmse: 1.55898\n",
      "[1600]\ttraining's rmse: 1.48502\tvalid_1's rmse: 1.55893\n",
      "[1700]\ttraining's rmse: 1.48107\tvalid_1's rmse: 1.55866\n",
      "[1800]\ttraining's rmse: 1.47718\tvalid_1's rmse: 1.55857\n",
      "[1900]\ttraining's rmse: 1.47327\tvalid_1's rmse: 1.55847\n",
      "[2000]\ttraining's rmse: 1.46946\tvalid_1's rmse: 1.55835\n",
      "[2100]\ttraining's rmse: 1.46566\tvalid_1's rmse: 1.55827\n",
      "[2200]\ttraining's rmse: 1.46196\tvalid_1's rmse: 1.55813\n",
      "[2300]\ttraining's rmse: 1.45828\tvalid_1's rmse: 1.55807\n",
      "[2400]\ttraining's rmse: 1.4545\tvalid_1's rmse: 1.55808\n",
      "[2500]\ttraining's rmse: 1.45083\tvalid_1's rmse: 1.55801\n",
      "[2600]\ttraining's rmse: 1.44723\tvalid_1's rmse: 1.55799\n",
      "[2700]\ttraining's rmse: 1.44368\tvalid_1's rmse: 1.55795\n",
      "Early stopping, best iteration is:\n",
      "[2561]\ttraining's rmse: 1.44862\tvalid_1's rmse: 1.5579\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.60496\tvalid_1's rmse: 1.61764\n",
      "[200]\ttraining's rmse: 1.5728\tvalid_1's rmse: 1.58927\n",
      "[300]\ttraining's rmse: 1.55708\tvalid_1's rmse: 1.57802\n",
      "[400]\ttraining's rmse: 1.5467\tvalid_1's rmse: 1.57251\n",
      "[500]\ttraining's rmse: 1.53848\tvalid_1's rmse: 1.56926\n",
      "[600]\ttraining's rmse: 1.53131\tvalid_1's rmse: 1.56703\n",
      "[700]\ttraining's rmse: 1.5251\tvalid_1's rmse: 1.56561\n",
      "[800]\ttraining's rmse: 1.51946\tvalid_1's rmse: 1.56454\n",
      "[900]\ttraining's rmse: 1.51439\tvalid_1's rmse: 1.56397\n",
      "[1000]\ttraining's rmse: 1.50963\tvalid_1's rmse: 1.56345\n",
      "[1100]\ttraining's rmse: 1.50491\tvalid_1's rmse: 1.56295\n",
      "[1200]\ttraining's rmse: 1.50048\tvalid_1's rmse: 1.5627\n",
      "[1300]\ttraining's rmse: 1.49605\tvalid_1's rmse: 1.56248\n",
      "[1400]\ttraining's rmse: 1.49174\tvalid_1's rmse: 1.56232\n",
      "[1500]\ttraining's rmse: 1.48761\tvalid_1's rmse: 1.56223\n",
      "[1600]\ttraining's rmse: 1.48359\tvalid_1's rmse: 1.56199\n",
      "[1700]\ttraining's rmse: 1.47965\tvalid_1's rmse: 1.56192\n",
      "[1800]\ttraining's rmse: 1.47565\tvalid_1's rmse: 1.56176\n",
      "[1900]\ttraining's rmse: 1.47187\tvalid_1's rmse: 1.56168\n",
      "[2000]\ttraining's rmse: 1.46798\tvalid_1's rmse: 1.56154\n",
      "[2100]\ttraining's rmse: 1.4641\tvalid_1's rmse: 1.56138\n",
      "[2200]\ttraining's rmse: 1.46037\tvalid_1's rmse: 1.56136\n",
      "[2300]\ttraining's rmse: 1.45658\tvalid_1's rmse: 1.56128\n",
      "[2400]\ttraining's rmse: 1.45303\tvalid_1's rmse: 1.56124\n",
      "[2500]\ttraining's rmse: 1.4494\tvalid_1's rmse: 1.56122\n",
      "[2600]\ttraining's rmse: 1.44584\tvalid_1's rmse: 1.56117\n",
      "[2700]\ttraining's rmse: 1.44221\tvalid_1's rmse: 1.56117\n",
      "[2800]\ttraining's rmse: 1.4387\tvalid_1's rmse: 1.5611\n",
      "[2900]\ttraining's rmse: 1.43526\tvalid_1's rmse: 1.56115\n",
      "Early stopping, best iteration is:\n",
      "[2783]\ttraining's rmse: 1.4393\tvalid_1's rmse: 1.56109\n",
      "CV score: 1.55531 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof_lgb_without_outliers = np.zeros(len(train_without_outliers))\n",
    "oof_lgb_outliers = np.zeros(len(train_outliers))\n",
    "predictions_lgb_without_outliers = np.zeros(len(test))\n",
    "feature_importance = pd.DataFrame()\n",
    "\n",
    "train_columns = [f for f in train_without_outliers.columns if f not in FEATS_EXCLUDED]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_without_outliers, train_without_outliers['outliers'].values)):    \n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_without_outliers.iloc[trn_idx][train_columns], label=train_without_outliers.iloc[trn_idx]['target'])\n",
    "    val_data = lgb.Dataset(train_without_outliers.iloc[val_idx][train_columns], label=train_without_outliers.iloc[val_idx]['target'])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof_lgb_without_outliers[val_idx] = clf.predict(train_without_outliers.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    oof_lgb_outliers += clf.predict(train_outliers[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    predictions_lgb_without_outliers += clf.predict(test[train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"Feature\"] = train_columns\n",
    "    fold_importance[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance[\"fold\"] = fold_ + 1\n",
    "    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(train_without_outliers.target.values, oof_lgb_without_outliers)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T16:13:06.884738Z",
     "start_time": "2019-02-07T16:13:06.134942Z"
    }
   },
   "outputs": [],
   "source": [
    "templete.merge(pd.DataFrame({'card_id':train_outliers.card_id, 'target': oof_lgb_outliers}).append(pd.DataFrame({'card_id':train_without_outliers.card_id, 'target': oof_lgb_without_outliers})), how='left').to_csv('./data_modeling/outliers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T08:12:44.905855Z",
     "start_time": "2019-02-14T08:12:43.357870Z"
    }
   },
   "outputs": [],
   "source": [
    "base = pd.read_csv('./data_modeling/base.csv')\n",
    "neg = pd.read_csv('./data_modeling/neg.csv')\n",
    "pos = pd.read_csv('./data_modeling/pos.csv')\n",
    "outliers = pd.read_csv('./data_modeling/outliers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T08:13:35.551112Z",
     "start_time": "2019-02-14T08:13:35.473932Z"
    }
   },
   "outputs": [],
   "source": [
    "layer2_train = pd.DataFrame({'card_id':base.card_id, 'base':base.target, 'neg':neg.target, 'pos':pos.target, 'outliers':outliers.target})\n",
    "layer2_train['target'] = train.target\n",
    "layer2_train.set_index('card_id', inplace=True)\n",
    "\n",
    "# outlier\n",
    "layer2_train['is_outliers'] = 0\n",
    "layer2_train.loc[layer2_train['target'] < -30, 'is_outliers'] = 1\n",
    "\n",
    "target = layer2_train.target.copy()\n",
    "del layer2_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-14T08:13:48.157594Z",
     "start_time": "2019-02-14T08:13:48.088457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>outliers</th>\n",
       "      <th>is_outliers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_92a2005557</th>\n",
       "      <td>-0.281289</td>\n",
       "      <td>-0.789168</td>\n",
       "      <td>0.473972</td>\n",
       "      <td>-0.284566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_3d0044924f</th>\n",
       "      <td>-0.483703</td>\n",
       "      <td>-1.294766</td>\n",
       "      <td>0.992636</td>\n",
       "      <td>0.218978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_d639edf6cd</th>\n",
       "      <td>0.745200</td>\n",
       "      <td>-1.530998</td>\n",
       "      <td>1.623683</td>\n",
       "      <td>0.595680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_186d6a6901</th>\n",
       "      <td>0.136627</td>\n",
       "      <td>-1.043530</td>\n",
       "      <td>0.958335</td>\n",
       "      <td>0.197117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_cdbd2c0db2</th>\n",
       "      <td>-0.025510</td>\n",
       "      <td>-0.778105</td>\n",
       "      <td>0.594380</td>\n",
       "      <td>-0.128851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_0894217f2f</th>\n",
       "      <td>-1.380128</td>\n",
       "      <td>-2.565628</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>-0.468703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_7e63323c00</th>\n",
       "      <td>-0.260393</td>\n",
       "      <td>-1.015265</td>\n",
       "      <td>0.632335</td>\n",
       "      <td>-0.326014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_dfa21fc124</th>\n",
       "      <td>0.103919</td>\n",
       "      <td>-1.539982</td>\n",
       "      <td>1.488595</td>\n",
       "      <td>-0.065392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_fe0fdac8ea</th>\n",
       "      <td>0.064726</td>\n",
       "      <td>-1.869386</td>\n",
       "      <td>1.096484</td>\n",
       "      <td>0.279655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_bf62c0b49d</th>\n",
       "      <td>-0.010490</td>\n",
       "      <td>-1.283262</td>\n",
       "      <td>1.098469</td>\n",
       "      <td>0.108912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_92853cdb2c</th>\n",
       "      <td>-0.605313</td>\n",
       "      <td>-1.180502</td>\n",
       "      <td>0.799281</td>\n",
       "      <td>-0.670848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_269d816788</th>\n",
       "      <td>-0.133771</td>\n",
       "      <td>-2.745241</td>\n",
       "      <td>1.918545</td>\n",
       "      <td>0.709638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_61d50d7057</th>\n",
       "      <td>0.442184</td>\n",
       "      <td>-1.294397</td>\n",
       "      <td>1.476425</td>\n",
       "      <td>0.616103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4e07413433</th>\n",
       "      <td>-0.483839</td>\n",
       "      <td>-2.030475</td>\n",
       "      <td>0.815029</td>\n",
       "      <td>-0.791130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_b6302b31c6</th>\n",
       "      <td>-0.568208</td>\n",
       "      <td>-1.195651</td>\n",
       "      <td>0.954891</td>\n",
       "      <td>-0.461175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_3b69154173</th>\n",
       "      <td>0.813941</td>\n",
       "      <td>-1.454892</td>\n",
       "      <td>1.252501</td>\n",
       "      <td>0.851880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_9feec11e78</th>\n",
       "      <td>-0.314497</td>\n",
       "      <td>-1.642530</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>-0.176523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_f6658dbefe</th>\n",
       "      <td>0.179351</td>\n",
       "      <td>-1.374297</td>\n",
       "      <td>0.807556</td>\n",
       "      <td>0.094076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4a7dda0f9e</th>\n",
       "      <td>0.028955</td>\n",
       "      <td>-1.108884</td>\n",
       "      <td>0.830273</td>\n",
       "      <td>0.188481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_6adae2a906</th>\n",
       "      <td>-1.342733</td>\n",
       "      <td>-1.455192</td>\n",
       "      <td>0.603119</td>\n",
       "      <td>-1.163620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_0b70ca7347</th>\n",
       "      <td>-0.161936</td>\n",
       "      <td>-0.925175</td>\n",
       "      <td>0.628271</td>\n",
       "      <td>-0.101604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_25b2509282</th>\n",
       "      <td>0.680382</td>\n",
       "      <td>-2.926511</td>\n",
       "      <td>1.675120</td>\n",
       "      <td>0.776912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_82fb11db22</th>\n",
       "      <td>-0.349573</td>\n",
       "      <td>-1.612096</td>\n",
       "      <td>0.977725</td>\n",
       "      <td>-0.029068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_e03db05bde</th>\n",
       "      <td>-0.435980</td>\n",
       "      <td>-1.440882</td>\n",
       "      <td>0.857967</td>\n",
       "      <td>-0.524358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_dcb7c76747</th>\n",
       "      <td>-0.066897</td>\n",
       "      <td>-0.737375</td>\n",
       "      <td>0.426626</td>\n",
       "      <td>-0.084263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_749cfc0c3a</th>\n",
       "      <td>0.430955</td>\n",
       "      <td>-3.562644</td>\n",
       "      <td>1.299665</td>\n",
       "      <td>0.775441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_4a97126360</th>\n",
       "      <td>-0.412358</td>\n",
       "      <td>-0.856061</td>\n",
       "      <td>0.475329</td>\n",
       "      <td>-0.337966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_17dea8d446</th>\n",
       "      <td>0.639632</td>\n",
       "      <td>-1.599657</td>\n",
       "      <td>1.450859</td>\n",
       "      <td>1.005681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_fcef0dfd67</th>\n",
       "      <td>-0.483122</td>\n",
       "      <td>-0.782012</td>\n",
       "      <td>0.464717</td>\n",
       "      <td>-0.350599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_82868156f0</th>\n",
       "      <td>-1.010258</td>\n",
       "      <td>-1.704674</td>\n",
       "      <td>0.842768</td>\n",
       "      <td>-0.479195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_fa343b1b60</th>\n",
       "      <td>-0.530806</td>\n",
       "      <td>-1.010888</td>\n",
       "      <td>0.661018</td>\n",
       "      <td>-0.427806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_8fb51d131f</th>\n",
       "      <td>-0.424422</td>\n",
       "      <td>-0.782327</td>\n",
       "      <td>0.438090</td>\n",
       "      <td>-0.387020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_ea7df02b8d</th>\n",
       "      <td>-0.184949</td>\n",
       "      <td>-0.757635</td>\n",
       "      <td>0.449998</td>\n",
       "      <td>-0.256931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_82554b8b1f</th>\n",
       "      <td>-0.002089</td>\n",
       "      <td>-0.762006</td>\n",
       "      <td>0.498166</td>\n",
       "      <td>0.053603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_ec1fdc9c13</th>\n",
       "      <td>-0.263643</td>\n",
       "      <td>-1.109898</td>\n",
       "      <td>0.973242</td>\n",
       "      <td>-0.217585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_be5a444ff5</th>\n",
       "      <td>-3.275350</td>\n",
       "      <td>-3.483533</td>\n",
       "      <td>0.622869</td>\n",
       "      <td>-0.975190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_6c40a68e73</th>\n",
       "      <td>0.472519</td>\n",
       "      <td>-1.607936</td>\n",
       "      <td>1.580748</td>\n",
       "      <td>0.661114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_d02dd24e29</th>\n",
       "      <td>-0.137295</td>\n",
       "      <td>-1.918841</td>\n",
       "      <td>1.509163</td>\n",
       "      <td>0.187623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_2e16d5537d</th>\n",
       "      <td>-1.021102</td>\n",
       "      <td>-2.218805</td>\n",
       "      <td>0.581961</td>\n",
       "      <td>-0.663336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_808ba69dff</th>\n",
       "      <td>-0.395303</td>\n",
       "      <td>-0.908271</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>-0.400099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_095bca2d92</th>\n",
       "      <td>-0.391182</td>\n",
       "      <td>-1.529494</td>\n",
       "      <td>0.802285</td>\n",
       "      <td>-0.558224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_123b4b8d1e</th>\n",
       "      <td>-4.281924</td>\n",
       "      <td>-3.994928</td>\n",
       "      <td>1.206533</td>\n",
       "      <td>-0.994399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_58e359763e</th>\n",
       "      <td>-0.662490</td>\n",
       "      <td>-1.645832</td>\n",
       "      <td>0.634376</td>\n",
       "      <td>-0.933560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_0032aebb26</th>\n",
       "      <td>-0.347483</td>\n",
       "      <td>-1.013533</td>\n",
       "      <td>0.570163</td>\n",
       "      <td>-0.332911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_3814ea6382</th>\n",
       "      <td>-0.235822</td>\n",
       "      <td>-1.044128</td>\n",
       "      <td>0.642893</td>\n",
       "      <td>-0.235994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_b9cd68366b</th>\n",
       "      <td>0.240494</td>\n",
       "      <td>-0.935903</td>\n",
       "      <td>0.751580</td>\n",
       "      <td>0.158041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_b860347cb0</th>\n",
       "      <td>-0.138225</td>\n",
       "      <td>-0.965709</td>\n",
       "      <td>0.694341</td>\n",
       "      <td>-0.173623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_debbad9dec</th>\n",
       "      <td>-0.803613</td>\n",
       "      <td>-1.432881</td>\n",
       "      <td>0.704877</td>\n",
       "      <td>-0.875852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_75a2251acf</th>\n",
       "      <td>-0.137042</td>\n",
       "      <td>-1.045107</td>\n",
       "      <td>0.853515</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_1f777cd9b3</th>\n",
       "      <td>-0.345618</td>\n",
       "      <td>-0.902437</td>\n",
       "      <td>0.484189</td>\n",
       "      <td>-0.298998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_598ecf1dfe</th>\n",
       "      <td>0.149546</td>\n",
       "      <td>-1.565968</td>\n",
       "      <td>1.214786</td>\n",
       "      <td>0.436992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_c2124fa8ce</th>\n",
       "      <td>0.017682</td>\n",
       "      <td>-2.643751</td>\n",
       "      <td>1.468252</td>\n",
       "      <td>0.591283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_64545039d3</th>\n",
       "      <td>-1.333560</td>\n",
       "      <td>-2.002102</td>\n",
       "      <td>0.597858</td>\n",
       "      <td>-0.961707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_9072609210</th>\n",
       "      <td>-0.190766</td>\n",
       "      <td>-1.074969</td>\n",
       "      <td>0.663777</td>\n",
       "      <td>-0.171823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_0443db161f</th>\n",
       "      <td>-0.186590</td>\n",
       "      <td>-1.954699</td>\n",
       "      <td>1.316198</td>\n",
       "      <td>-0.283272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_963962de2c</th>\n",
       "      <td>0.232064</td>\n",
       "      <td>-1.478663</td>\n",
       "      <td>1.082887</td>\n",
       "      <td>0.147998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_1314773c0b</th>\n",
       "      <td>1.154728</td>\n",
       "      <td>-2.888808</td>\n",
       "      <td>2.777633</td>\n",
       "      <td>1.845068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_7666735b3d</th>\n",
       "      <td>-0.280058</td>\n",
       "      <td>-1.573930</td>\n",
       "      <td>1.401777</td>\n",
       "      <td>0.246596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_73f5a0efd0</th>\n",
       "      <td>-2.503826</td>\n",
       "      <td>-2.366929</td>\n",
       "      <td>0.446634</td>\n",
       "      <td>-2.602847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_92c9984c58</th>\n",
       "      <td>-0.306724</td>\n",
       "      <td>-1.028544</td>\n",
       "      <td>0.689041</td>\n",
       "      <td>-0.377503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201917 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     base       neg       pos  outliers  is_outliers\n",
       "card_id                                                             \n",
       "C_ID_92a2005557 -0.281289 -0.789168  0.473972 -0.284566            0\n",
       "C_ID_3d0044924f -0.483703 -1.294766  0.992636  0.218978            0\n",
       "C_ID_d639edf6cd  0.745200 -1.530998  1.623683  0.595680            0\n",
       "C_ID_186d6a6901  0.136627 -1.043530  0.958335  0.197117            0\n",
       "C_ID_cdbd2c0db2 -0.025510 -0.778105  0.594380 -0.128851            0\n",
       "C_ID_0894217f2f -1.380128 -2.565628  0.689279 -0.468703            0\n",
       "C_ID_7e63323c00 -0.260393 -1.015265  0.632335 -0.326014            0\n",
       "C_ID_dfa21fc124  0.103919 -1.539982  1.488595 -0.065392            0\n",
       "C_ID_fe0fdac8ea  0.064726 -1.869386  1.096484  0.279655            0\n",
       "C_ID_bf62c0b49d -0.010490 -1.283262  1.098469  0.108912            0\n",
       "C_ID_92853cdb2c -0.605313 -1.180502  0.799281 -0.670848            0\n",
       "C_ID_269d816788 -0.133771 -2.745241  1.918545  0.709638            0\n",
       "C_ID_61d50d7057  0.442184 -1.294397  1.476425  0.616103            0\n",
       "C_ID_4e07413433 -0.483839 -2.030475  0.815029 -0.791130            0\n",
       "C_ID_b6302b31c6 -0.568208 -1.195651  0.954891 -0.461175            0\n",
       "C_ID_3b69154173  0.813941 -1.454892  1.252501  0.851880            0\n",
       "C_ID_9feec11e78 -0.314497 -1.642530  0.806584 -0.176523            0\n",
       "C_ID_f6658dbefe  0.179351 -1.374297  0.807556  0.094076            0\n",
       "C_ID_4a7dda0f9e  0.028955 -1.108884  0.830273  0.188481            0\n",
       "C_ID_6adae2a906 -1.342733 -1.455192  0.603119 -1.163620            0\n",
       "C_ID_0b70ca7347 -0.161936 -0.925175  0.628271 -0.101604            0\n",
       "C_ID_25b2509282  0.680382 -2.926511  1.675120  0.776912            0\n",
       "C_ID_82fb11db22 -0.349573 -1.612096  0.977725 -0.029068            0\n",
       "C_ID_e03db05bde -0.435980 -1.440882  0.857967 -0.524358            0\n",
       "C_ID_dcb7c76747 -0.066897 -0.737375  0.426626 -0.084263            0\n",
       "C_ID_749cfc0c3a  0.430955 -3.562644  1.299665  0.775441            0\n",
       "C_ID_4a97126360 -0.412358 -0.856061  0.475329 -0.337966            0\n",
       "C_ID_17dea8d446  0.639632 -1.599657  1.450859  1.005681            0\n",
       "C_ID_fcef0dfd67 -0.483122 -0.782012  0.464717 -0.350599            0\n",
       "C_ID_82868156f0 -1.010258 -1.704674  0.842768 -0.479195            0\n",
       "...                   ...       ...       ...       ...          ...\n",
       "C_ID_fa343b1b60 -0.530806 -1.010888  0.661018 -0.427806            0\n",
       "C_ID_8fb51d131f -0.424422 -0.782327  0.438090 -0.387020            0\n",
       "C_ID_ea7df02b8d -0.184949 -0.757635  0.449998 -0.256931            0\n",
       "C_ID_82554b8b1f -0.002089 -0.762006  0.498166  0.053603            0\n",
       "C_ID_ec1fdc9c13 -0.263643 -1.109898  0.973242 -0.217585            0\n",
       "C_ID_be5a444ff5 -3.275350 -3.483533  0.622869 -0.975190            0\n",
       "C_ID_6c40a68e73  0.472519 -1.607936  1.580748  0.661114            0\n",
       "C_ID_d02dd24e29 -0.137295 -1.918841  1.509163  0.187623            0\n",
       "C_ID_2e16d5537d -1.021102 -2.218805  0.581961 -0.663336            0\n",
       "C_ID_808ba69dff -0.395303 -0.908271  0.494118 -0.400099            0\n",
       "C_ID_095bca2d92 -0.391182 -1.529494  0.802285 -0.558224            0\n",
       "C_ID_123b4b8d1e -4.281924 -3.994928  1.206533 -0.994399            0\n",
       "C_ID_58e359763e -0.662490 -1.645832  0.634376 -0.933560            0\n",
       "C_ID_0032aebb26 -0.347483 -1.013533  0.570163 -0.332911            0\n",
       "C_ID_3814ea6382 -0.235822 -1.044128  0.642893 -0.235994            0\n",
       "C_ID_b9cd68366b  0.240494 -0.935903  0.751580  0.158041            0\n",
       "C_ID_b860347cb0 -0.138225 -0.965709  0.694341 -0.173623            0\n",
       "C_ID_debbad9dec -0.803613 -1.432881  0.704877 -0.875852            0\n",
       "C_ID_75a2251acf -0.137042 -1.045107  0.853515  0.020714            0\n",
       "C_ID_1f777cd9b3 -0.345618 -0.902437  0.484189 -0.298998            0\n",
       "C_ID_598ecf1dfe  0.149546 -1.565968  1.214786  0.436992            0\n",
       "C_ID_c2124fa8ce  0.017682 -2.643751  1.468252  0.591283            0\n",
       "C_ID_64545039d3 -1.333560 -2.002102  0.597858 -0.961707            0\n",
       "C_ID_9072609210 -0.190766 -1.074969  0.663777 -0.171823            0\n",
       "C_ID_0443db161f -0.186590 -1.954699  1.316198 -0.283272            0\n",
       "C_ID_963962de2c  0.232064 -1.478663  1.082887  0.147998            0\n",
       "C_ID_1314773c0b  1.154728 -2.888808  2.777633  1.845068            0\n",
       "C_ID_7666735b3d -0.280058 -1.573930  1.401777  0.246596            0\n",
       "C_ID_73f5a0efd0 -2.503826 -2.366929  0.446634 -2.602847            0\n",
       "C_ID_92c9984c58 -0.306724 -1.028544  0.689041 -0.377503            0\n",
       "\n",
       "[201917 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T05:20:24.777361Z",
     "start_time": "2019-02-08T05:20:24.770418Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.001,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         \"random_state\": 4590}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T05:20:25.116989Z",
     "start_time": "2019-02-08T05:20:25.113849Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATS_EXCLUDED = ['is_outliers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T05:22:31.528661Z",
     "start_time": "2019-02-08T05:21:27.670448Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.81218\tvalid_1's rmse: 3.81847\n",
      "[200]\ttraining's rmse: 3.78065\tvalid_1's rmse: 3.78953\n",
      "[300]\ttraining's rmse: 3.75419\tvalid_1's rmse: 3.76559\n",
      "[400]\ttraining's rmse: 3.73195\tvalid_1's rmse: 3.74591\n",
      "[500]\ttraining's rmse: 3.71312\tvalid_1's rmse: 3.72952\n",
      "[600]\ttraining's rmse: 3.69724\tvalid_1's rmse: 3.71607\n",
      "[700]\ttraining's rmse: 3.68376\tvalid_1's rmse: 3.70489\n",
      "[800]\ttraining's rmse: 3.67232\tvalid_1's rmse: 3.69585\n",
      "[900]\ttraining's rmse: 3.66256\tvalid_1's rmse: 3.68838\n",
      "[1000]\ttraining's rmse: 3.65421\tvalid_1's rmse: 3.68224\n",
      "[1100]\ttraining's rmse: 3.64695\tvalid_1's rmse: 3.67729\n",
      "[1200]\ttraining's rmse: 3.64067\tvalid_1's rmse: 3.67325\n",
      "[1300]\ttraining's rmse: 3.63518\tvalid_1's rmse: 3.66986\n",
      "[1400]\ttraining's rmse: 3.63037\tvalid_1's rmse: 3.66713\n",
      "[1500]\ttraining's rmse: 3.62605\tvalid_1's rmse: 3.66487\n",
      "[1600]\ttraining's rmse: 3.62226\tvalid_1's rmse: 3.66309\n",
      "[1700]\ttraining's rmse: 3.61879\tvalid_1's rmse: 3.66169\n",
      "[1800]\ttraining's rmse: 3.61565\tvalid_1's rmse: 3.66052\n",
      "[1900]\ttraining's rmse: 3.61275\tvalid_1's rmse: 3.65962\n",
      "[2000]\ttraining's rmse: 3.6101\tvalid_1's rmse: 3.65901\n",
      "[2100]\ttraining's rmse: 3.60765\tvalid_1's rmse: 3.65848\n",
      "[2200]\ttraining's rmse: 3.60533\tvalid_1's rmse: 3.65807\n",
      "[2300]\ttraining's rmse: 3.60317\tvalid_1's rmse: 3.65779\n",
      "[2400]\ttraining's rmse: 3.60112\tvalid_1's rmse: 3.65761\n",
      "[2500]\ttraining's rmse: 3.59913\tvalid_1's rmse: 3.65739\n",
      "[2600]\ttraining's rmse: 3.59724\tvalid_1's rmse: 3.65727\n",
      "[2700]\ttraining's rmse: 3.59544\tvalid_1's rmse: 3.65729\n",
      "[2800]\ttraining's rmse: 3.59372\tvalid_1's rmse: 3.65731\n",
      "Early stopping, best iteration is:\n",
      "[2663]\ttraining's rmse: 3.59608\tvalid_1's rmse: 3.65723\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.81176\tvalid_1's rmse: 3.81889\n",
      "[200]\ttraining's rmse: 3.77999\tvalid_1's rmse: 3.78998\n",
      "[300]\ttraining's rmse: 3.7534\tvalid_1's rmse: 3.76615\n",
      "[400]\ttraining's rmse: 3.73098\tvalid_1's rmse: 3.74663\n",
      "[500]\ttraining's rmse: 3.71211\tvalid_1's rmse: 3.73063\n",
      "[600]\ttraining's rmse: 3.69619\tvalid_1's rmse: 3.71751\n",
      "[700]\ttraining's rmse: 3.68274\tvalid_1's rmse: 3.70679\n",
      "[800]\ttraining's rmse: 3.67128\tvalid_1's rmse: 3.69811\n",
      "[900]\ttraining's rmse: 3.66147\tvalid_1's rmse: 3.69108\n",
      "[1000]\ttraining's rmse: 3.65311\tvalid_1's rmse: 3.6854\n",
      "[1100]\ttraining's rmse: 3.64577\tvalid_1's rmse: 3.68078\n",
      "[1200]\ttraining's rmse: 3.63939\tvalid_1's rmse: 3.67707\n",
      "[1300]\ttraining's rmse: 3.63384\tvalid_1's rmse: 3.67404\n",
      "[1400]\ttraining's rmse: 3.62893\tvalid_1's rmse: 3.67169\n",
      "[1500]\ttraining's rmse: 3.62457\tvalid_1's rmse: 3.66983\n",
      "[1600]\ttraining's rmse: 3.62068\tvalid_1's rmse: 3.6684\n",
      "[1700]\ttraining's rmse: 3.61719\tvalid_1's rmse: 3.66722\n",
      "[1800]\ttraining's rmse: 3.614\tvalid_1's rmse: 3.66631\n",
      "[1900]\ttraining's rmse: 3.61105\tvalid_1's rmse: 3.6656\n",
      "[2000]\ttraining's rmse: 3.60832\tvalid_1's rmse: 3.66506\n",
      "[2100]\ttraining's rmse: 3.60576\tvalid_1's rmse: 3.66464\n",
      "[2200]\ttraining's rmse: 3.60344\tvalid_1's rmse: 3.6644\n",
      "[2300]\ttraining's rmse: 3.60118\tvalid_1's rmse: 3.66413\n",
      "[2400]\ttraining's rmse: 3.59906\tvalid_1's rmse: 3.66405\n",
      "[2500]\ttraining's rmse: 3.59701\tvalid_1's rmse: 3.66404\n",
      "Early stopping, best iteration is:\n",
      "[2382]\ttraining's rmse: 3.59945\tvalid_1's rmse: 3.66402\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.81521\tvalid_1's rmse: 3.80725\n",
      "[200]\ttraining's rmse: 3.78385\tvalid_1's rmse: 3.7783\n",
      "[300]\ttraining's rmse: 3.7575\tvalid_1's rmse: 3.75438\n",
      "[400]\ttraining's rmse: 3.73537\tvalid_1's rmse: 3.73457\n",
      "[500]\ttraining's rmse: 3.71668\tvalid_1's rmse: 3.71815\n",
      "[600]\ttraining's rmse: 3.70093\tvalid_1's rmse: 3.70453\n",
      "[700]\ttraining's rmse: 3.68757\tvalid_1's rmse: 3.69321\n",
      "[800]\ttraining's rmse: 3.67619\tvalid_1's rmse: 3.68388\n",
      "[900]\ttraining's rmse: 3.66649\tvalid_1's rmse: 3.67615\n",
      "[1000]\ttraining's rmse: 3.65822\tvalid_1's rmse: 3.66976\n",
      "[1100]\ttraining's rmse: 3.65105\tvalid_1's rmse: 3.66447\n",
      "[1200]\ttraining's rmse: 3.64479\tvalid_1's rmse: 3.66005\n",
      "[1300]\ttraining's rmse: 3.63926\tvalid_1's rmse: 3.65638\n",
      "[1400]\ttraining's rmse: 3.6344\tvalid_1's rmse: 3.65341\n",
      "[1500]\ttraining's rmse: 3.63016\tvalid_1's rmse: 3.65092\n",
      "[1600]\ttraining's rmse: 3.62633\tvalid_1's rmse: 3.64886\n",
      "[1700]\ttraining's rmse: 3.62292\tvalid_1's rmse: 3.64711\n",
      "[1800]\ttraining's rmse: 3.61979\tvalid_1's rmse: 3.64565\n",
      "[1900]\ttraining's rmse: 3.61692\tvalid_1's rmse: 3.64446\n",
      "[2000]\ttraining's rmse: 3.61422\tvalid_1's rmse: 3.64351\n",
      "[2100]\ttraining's rmse: 3.61175\tvalid_1's rmse: 3.64265\n",
      "[2200]\ttraining's rmse: 3.60945\tvalid_1's rmse: 3.64201\n",
      "[2300]\ttraining's rmse: 3.60725\tvalid_1's rmse: 3.64149\n",
      "[2400]\ttraining's rmse: 3.60517\tvalid_1's rmse: 3.64101\n",
      "[2500]\ttraining's rmse: 3.60316\tvalid_1's rmse: 3.64065\n",
      "[2600]\ttraining's rmse: 3.60124\tvalid_1's rmse: 3.64027\n",
      "[2700]\ttraining's rmse: 3.5994\tvalid_1's rmse: 3.63997\n",
      "[2800]\ttraining's rmse: 3.59764\tvalid_1's rmse: 3.63977\n",
      "[2900]\ttraining's rmse: 3.59596\tvalid_1's rmse: 3.63957\n",
      "[3000]\ttraining's rmse: 3.59429\tvalid_1's rmse: 3.63948\n",
      "[3100]\ttraining's rmse: 3.59269\tvalid_1's rmse: 3.63935\n",
      "[3200]\ttraining's rmse: 3.59115\tvalid_1's rmse: 3.63924\n",
      "[3300]\ttraining's rmse: 3.5896\tvalid_1's rmse: 3.6392\n",
      "[3400]\ttraining's rmse: 3.58814\tvalid_1's rmse: 3.63916\n",
      "[3500]\ttraining's rmse: 3.58665\tvalid_1's rmse: 3.63918\n",
      "[3600]\ttraining's rmse: 3.58533\tvalid_1's rmse: 3.63919\n",
      "Early stopping, best iteration is:\n",
      "[3462]\ttraining's rmse: 3.58722\tvalid_1's rmse: 3.63914\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.81283\tvalid_1's rmse: 3.81558\n",
      "[200]\ttraining's rmse: 3.78139\tvalid_1's rmse: 3.78585\n",
      "[300]\ttraining's rmse: 3.75499\tvalid_1's rmse: 3.76119\n",
      "[400]\ttraining's rmse: 3.7328\tvalid_1's rmse: 3.74083\n",
      "[500]\ttraining's rmse: 3.71407\tvalid_1's rmse: 3.72408\n",
      "[600]\ttraining's rmse: 3.69824\tvalid_1's rmse: 3.71021\n",
      "[700]\ttraining's rmse: 3.68477\tvalid_1's rmse: 3.69883\n",
      "[800]\ttraining's rmse: 3.67331\tvalid_1's rmse: 3.68947\n",
      "[900]\ttraining's rmse: 3.66351\tvalid_1's rmse: 3.68192\n",
      "[1000]\ttraining's rmse: 3.65508\tvalid_1's rmse: 3.67557\n",
      "[1100]\ttraining's rmse: 3.64778\tvalid_1's rmse: 3.67044\n",
      "[1200]\ttraining's rmse: 3.64146\tvalid_1's rmse: 3.66625\n",
      "[1300]\ttraining's rmse: 3.63587\tvalid_1's rmse: 3.66286\n",
      "[1400]\ttraining's rmse: 3.63095\tvalid_1's rmse: 3.66021\n",
      "[1500]\ttraining's rmse: 3.62658\tvalid_1's rmse: 3.65802\n",
      "[1600]\ttraining's rmse: 3.62267\tvalid_1's rmse: 3.65624\n",
      "[1700]\ttraining's rmse: 3.61914\tvalid_1's rmse: 3.65489\n",
      "[1800]\ttraining's rmse: 3.61597\tvalid_1's rmse: 3.65377\n",
      "[1900]\ttraining's rmse: 3.61299\tvalid_1's rmse: 3.65293\n",
      "[2000]\ttraining's rmse: 3.61027\tvalid_1's rmse: 3.65232\n",
      "[2100]\ttraining's rmse: 3.60777\tvalid_1's rmse: 3.65181\n",
      "[2200]\ttraining's rmse: 3.60544\tvalid_1's rmse: 3.65148\n",
      "[2300]\ttraining's rmse: 3.60319\tvalid_1's rmse: 3.65132\n",
      "[2400]\ttraining's rmse: 3.60105\tvalid_1's rmse: 3.65116\n",
      "[2500]\ttraining's rmse: 3.59908\tvalid_1's rmse: 3.65106\n",
      "[2600]\ttraining's rmse: 3.59716\tvalid_1's rmse: 3.65107\n",
      "[2700]\ttraining's rmse: 3.5953\tvalid_1's rmse: 3.65112\n",
      "Early stopping, best iteration is:\n",
      "[2520]\ttraining's rmse: 3.59869\tvalid_1's rmse: 3.65105\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 3.8127\tvalid_1's rmse: 3.81602\n",
      "[200]\ttraining's rmse: 3.78122\tvalid_1's rmse: 3.7865\n",
      "[300]\ttraining's rmse: 3.75477\tvalid_1's rmse: 3.76208\n",
      "[400]\ttraining's rmse: 3.73252\tvalid_1's rmse: 3.74185\n",
      "[500]\ttraining's rmse: 3.71372\tvalid_1's rmse: 3.72521\n",
      "[600]\ttraining's rmse: 3.69785\tvalid_1's rmse: 3.71143\n",
      "[700]\ttraining's rmse: 3.68442\tvalid_1's rmse: 3.70011\n",
      "[800]\ttraining's rmse: 3.67306\tvalid_1's rmse: 3.69082\n",
      "[900]\ttraining's rmse: 3.66329\tvalid_1's rmse: 3.68315\n",
      "[1000]\ttraining's rmse: 3.65495\tvalid_1's rmse: 3.67691\n",
      "[1100]\ttraining's rmse: 3.64772\tvalid_1's rmse: 3.67181\n",
      "[1200]\ttraining's rmse: 3.64143\tvalid_1's rmse: 3.6676\n",
      "[1300]\ttraining's rmse: 3.63594\tvalid_1's rmse: 3.66422\n",
      "[1400]\ttraining's rmse: 3.63106\tvalid_1's rmse: 3.66155\n",
      "[1500]\ttraining's rmse: 3.62673\tvalid_1's rmse: 3.65933\n",
      "[1600]\ttraining's rmse: 3.62293\tvalid_1's rmse: 3.65754\n",
      "[1700]\ttraining's rmse: 3.61946\tvalid_1's rmse: 3.65604\n",
      "[1800]\ttraining's rmse: 3.61634\tvalid_1's rmse: 3.65483\n",
      "[1900]\ttraining's rmse: 3.61344\tvalid_1's rmse: 3.65387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttraining's rmse: 3.61077\tvalid_1's rmse: 3.6532\n",
      "[2100]\ttraining's rmse: 3.60826\tvalid_1's rmse: 3.65266\n",
      "[2200]\ttraining's rmse: 3.60595\tvalid_1's rmse: 3.65218\n",
      "[2300]\ttraining's rmse: 3.60374\tvalid_1's rmse: 3.65191\n",
      "[2400]\ttraining's rmse: 3.60164\tvalid_1's rmse: 3.65171\n",
      "[2500]\ttraining's rmse: 3.59963\tvalid_1's rmse: 3.65161\n",
      "[2600]\ttraining's rmse: 3.59772\tvalid_1's rmse: 3.65145\n",
      "[2700]\ttraining's rmse: 3.59585\tvalid_1's rmse: 3.65151\n",
      "Early stopping, best iteration is:\n",
      "[2598]\ttraining's rmse: 3.59776\tvalid_1's rmse: 3.65145\n",
      "CV score: 3.65259 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof_train = np.zeros(len(layer2_train))\n",
    "\n",
    "train_columns = [f for f in layer2_train.columns if f not in FEATS_EXCLUDED]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(layer2_train, layer2_train.is_outliers)):    \n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(layer2_train.iloc[trn_idx][train_columns], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(layer2_train.iloc[val_idx][train_columns], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof_train[val_idx] = clf.predict(layer2_train.iloc[val_idx][train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(target.values, oof_train)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T05:23:33.661866Z",
     "start_time": "2019-02-08T05:23:32.177912Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T05:39:13.260769Z",
     "start_time": "2019-02-08T05:37:31.655016Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "cv:  3.6540617427495166\n",
      "fold n°1\n",
      "cv:  3.659229209052886\n",
      "fold n°2\n",
      "cv:  3.6411249591634394\n",
      "fold n°3\n",
      "cv:  3.6470496971875668\n",
      "fold n°4\n",
      "cv:  3.6470064974884675\n",
      "CV score: 3.64970 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof_train = np.zeros(len(layer2_train))\n",
    "\n",
    "train_columns = [f for f in layer2_train.columns if f not in FEATS_EXCLUDED]\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(layer2_train, layer2_train.is_outliers)):    \n",
    "    rf = RandomForestRegressor(n_estimators=400, n_jobs=-1, max_depth=4, random_state = 5, bootstrap=True)\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    x_trn_data = layer2_train.iloc[trn_idx][train_columns]\n",
    "    y_trn_data = target.iloc[trn_idx]\n",
    "    x_val_data = layer2_train.iloc[val_idx][train_columns]\n",
    "    y_val_data = target.iloc[val_idx]\n",
    "    \n",
    "    rf.fit(x_trn_data, y_trn_data)    \n",
    "    \n",
    "    print(\"cv: \", mean_squared_error(y_val_data, rf.predict(x_val_data))**0.5)\n",
    "    oof_train[val_idx] = rf.predict(x_val_data)\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(target.values, oof_train)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T05:55:57.986359Z",
     "start_time": "2019-02-08T05:55:57.982370Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, LeakyReLU, Dropout, Lambda, subtract, ReLU\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T05:44:09.771256Z",
     "start_time": "2019-02-08T05:44:09.768100Z"
    }
   },
   "outputs": [],
   "source": [
    "del layer2_train['is_outliers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T05:47:13.342324Z",
     "start_time": "2019-02-08T05:47:13.243455Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(layer2_train, target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T06:33:33.727236Z",
     "start_time": "2019-02-08T06:33:33.717266Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_embedding(shape, dimensions):\n",
    "    inp = Input(shape=shape)\n",
    "    x = inp\n",
    "\n",
    "    x = Dense(512)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(8)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(4)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Dense(dimensions)(x)\n",
    "    out = x\n",
    "\n",
    "    return Model(inputs=inp, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T06:33:34.261675Z",
     "start_time": "2019-02-08T06:33:34.099747Z"
    }
   },
   "outputs": [],
   "source": [
    "model = build_embedding((4,), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T06:33:34.458515Z",
     "start_time": "2019-02-08T06:33:34.433550Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.01, decay=0, amsgrad=False)\n",
    "model.compile(optimizer=opt, loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T06:33:34.728891Z",
     "start_time": "2019-02-08T06:33:34.725899Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T06:35:37.051528Z",
     "start_time": "2019-02-08T06:33:34.997911Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 1/1\n",
      "141341/141341 [==============================] - 7s 53us/step - loss: 14.6602 - val_loss: 14.4497\n",
      "val rmse: 3.8012766652264265, train rmse: 3.8288602959272144\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 2/2\n",
      "141341/141341 [==============================] - 7s 47us/step - loss: 14.6958 - val_loss: 14.5150\n",
      "val rmse: 3.809855205756602, train rmse: 3.8335137983740117\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 3/3\n",
      "141341/141341 [==============================] - 7s 49us/step - loss: 14.7981 - val_loss: 14.7757\n",
      "val rmse: 3.843912984444872, train rmse: 3.8468272233135625\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 4/4\n",
      "141341/141341 [==============================] - 7s 49us/step - loss: 14.8532 - val_loss: 14.7751\n",
      "val rmse: 3.8438395090083737, train rmse: 3.8539806260136884\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 5/5\n",
      "141341/141341 [==============================] - 7s 49us/step - loss: 14.8528 - val_loss: 14.7727\n",
      "val rmse: 3.8435262398392447, train rmse: 3.8539270376876993\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 6/6\n",
      "141341/141341 [==============================] - 7s 47us/step - loss: 14.8514 - val_loss: 14.7748\n",
      "val rmse: 3.8438045309808433, train rmse: 3.853755803379949\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 7/7\n",
      "141341/141341 [==============================] - 7s 50us/step - loss: 14.8509 - val_loss: 14.7748\n",
      "val rmse: 3.8438033368106987, train rmse: 3.853683185289836\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 8/8\n",
      "141341/141341 [==============================] - 7s 50us/step - loss: 14.8515 - val_loss: 14.7779\n",
      "val rmse: 3.844199257789153, train rmse: 3.8537588107510894\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 9/9\n",
      "141341/141341 [==============================] - 7s 50us/step - loss: 14.8514 - val_loss: 14.7727\n",
      "val rmse: 3.8435289858743555, train rmse: 3.853749630474786\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 10/10\n",
      "141341/141341 [==============================] - 7s 50us/step - loss: 14.8508 - val_loss: 14.7737\n",
      "val rmse: 3.8436611963101788, train rmse: 3.8536764663103695\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 11/11\n",
      "141341/141341 [==============================] - 8s 59us/step - loss: 14.8510 - val_loss: 14.7732\n",
      "val rmse: 3.8435888086505927, train rmse: 3.8537044415894837\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 12/12\n",
      "141341/141341 [==============================] - 7s 50us/step - loss: 14.8514 - val_loss: 14.7748\n",
      "val rmse: 3.8437992236133915, train rmse: 3.853752705287772\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 13/13\n",
      "141341/141341 [==============================] - 7s 50us/step - loss: 14.8512 - val_loss: 14.7740\n",
      "val rmse: 3.843691552175681, train rmse: 3.85372921817724\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 14/14\n",
      "141341/141341 [==============================] - 7s 47us/step - loss: 14.8512 - val_loss: 14.7731\n",
      "val rmse: 3.8435834291900415, train rmse: 3.8537227042939155\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 15/15\n",
      "141341/141341 [==============================] - 7s 48us/step - loss: 14.8535 - val_loss: 14.7741\n",
      "val rmse: 3.8437084509838817, train rmse: 3.854027593254567\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 16/16\n",
      "141341/141341 [==============================] - 7s 48us/step - loss: 14.8516 - val_loss: 14.7745\n",
      "val rmse: 3.84375947602275, train rmse: 3.8537827721085334\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 17/17\n",
      "141341/141341 [==============================] - 7s 51us/step - loss: 14.8513 - val_loss: 14.7729\n",
      "val rmse: 3.8435465399820874, train rmse: 3.8537439859942495\n",
      "Train on 141341 samples, validate on 60576 samples\n",
      "Epoch 18/18\n",
      " 36096/141341 [======>.......................] - ETA: 5s - loss: 15.8282"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-009d8d7f52c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                     validation_data=(val_x, val_y))\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"val rmse: {}, train rmse: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    res = model.fit(x=train_x,\n",
    "                    y=train_y,\n",
    "                    batch_size=128,\n",
    "                    initial_epoch=epoch,\n",
    "                    epochs=epoch + 1,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(val_x, val_y))\n",
    "    \n",
    "    print(\"val rmse: {}, train rmse: {}\".format(res.history['val_loss'][0] ** 0.5, res.history['loss'][0] ** 0.5))\n",
    "    train_loss = res.history['loss'][0]\n",
    "    val_loss = res.history['val_loss'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
